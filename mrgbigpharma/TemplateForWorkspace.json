{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "mrgbigpharma"
		},
		"AmazonS3Compatible2_secretAccessKey": {
			"type": "secureString",
			"metadata": "Secure string for 'secretAccessKey' of 'AmazonS3Compatible2'"
		},
		"MinIoS3_secretAccessKey": {
			"type": "secureString",
			"metadata": "Secure string for 'secretAccessKey' of 'MinIoS3'"
		},
		"S3MinIO_secretAccessKey": {
			"type": "secureString",
			"metadata": "Secure string for 'secretAccessKey' of 'S3MinIO'"
		},
		"mrgbigpharma-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'mrgbigpharma-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:mrgbigpharma.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"AmazonS3Compatible2_properties_typeProperties_accessKeyId": {
			"type": "string",
			"defaultValue": "minioadmin"
		},
		"AzureKeyVault_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "https://keylakehouse.vault.azure.net/"
		},
		"MinIoS3_properties_typeProperties_accessKeyId": {
			"type": "string",
			"defaultValue": "minioadmin"
		},
		"MySqlErp_properties_typeProperties_server": {
			"type": "string",
			"defaultValue": "@{linkedService().Server}"
		},
		"MySqlErp_properties_typeProperties_database": {
			"type": "string",
			"defaultValue": "@{linkedService().Database}"
		},
		"MySqlErp_properties_typeProperties_username": {
			"type": "string",
			"defaultValue": "@{linkedService().User}"
		},
		"MySqlPassword_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "https://keylakehouse.vault.azure.net/"
		},
		"S3MinIO_properties_typeProperties_accessKeyId": {
			"type": "string",
			"defaultValue": "minioadmin"
		},
		"eceuropaeu_inflation_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/ei_cphi_m$defaultview/?format=TSV&compressed=false"
		},
		"mrgbigpharma-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://bigpharma.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/Extract Erp Data')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "List of Tables",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "MySqlSource",
								"query": "call Set_Initial_Dates_In_Tables();\n\nselect table_name, last_update_date,elt_last_update_date From serwer296707_pharma.logs;"
							},
							"dataset": {
								"referenceName": "MySql_Erp_List_Tables",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "Copy For Each Table",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "List of Tables",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('List of Tables').output.value",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Extract Table Copy To ADLS_copy1",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "MySqlSource",
											"query": {
												"value": "@concat(\n    'SELECT * FROM ', \n    item().table_name,\n    ' WHERE update_date <= STR_TO_DATE(''', item().last_update_date, ''', ''%Y-%m-%dT%H:%i:%s'') ',\n    'AND update_date > STR_TO_DATE(''', item().elt_last_update_date, ''', ''%Y-%m-%dT%H:%i:%s'');'\n)\n",
												"type": "Expression"
											}
										},
										"sink": {
											"type": "ParquetSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings",
												"copyBehavior": "FlattenHierarchy"
											},
											"formatSettings": {
												"type": "ParquetWriteSettings"
											}
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "MySql_Erp_Dynamic_Load",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "Bronze_Parquet",
											"type": "DatasetReference",
											"parameters": {
												"filename": {
													"value": "@if( equals(item().table_name, 'logs') , \n     concat(item().table_name,'.parquet'),\n     concat(item().table_name,'_',pipeline().TriggerTime,'.parquet'))",
													"type": "Expression"
												},
												"foldername": "@item().table_name"
											}
										}
									]
								}
							]
						}
					},
					{
						"name": "Set Last Update Date",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "Copy For Each Table",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "MySqlSource",
								"query": "call serwer296707_pharma.Set_Last_Update_Date;\n\nselect last_update_date,elt_last_update_date From serwer296707_pharma.logs;"
							},
							"dataset": {
								"referenceName": "MySql_Erp_List_Tables",
								"type": "DatasetReference",
								"parameters": {}
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Brozne"
				},
				"annotations": [],
				"lastPublishTime": "2025-03-27T05:52:42Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/MySql_Erp_List_Tables')]",
				"[concat(variables('workspaceId'), '/datasets/MySql_Erp_Dynamic_Load')]",
				"[concat(variables('workspaceId'), '/datasets/Bronze_Parquet')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Extract MinIO Data')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Distributors Data MinIo",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "LOAD_DISTRIBUTORS_DATA_PY",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 2,
								"spark.dynamicAllocation.maxExecutors": 2
							},
							"driverSize": "Small",
							"numExecutors": 2,
							"authentication": {
								"type": "MSI"
							}
						}
					},
					{
						"name": "Pharmacies Data MinIo",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "Distributors Data MinIo",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 1,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "LOAD_PHARMACIES_DATA_PY",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 2,
								"spark.dynamicAllocation.maxExecutors": 2
							},
							"driverSize": "Small",
							"numExecutors": 2,
							"authentication": {
								"type": "MSI"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Brozne"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/LOAD_DISTRIBUTORS_DATA_PY')]",
				"[concat(variables('workspaceId'), '/bigDataPools/sparkpool32')]",
				"[concat(variables('workspaceId'), '/notebooks/LOAD_PHARMACIES_DATA_PY')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Extract_Load_Eurostat')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Inflation_load",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "HttpReadSettings",
									"requestMethod": "GET",
									"requestTimeout": ""
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": "freq,unit,s_adj,indic,geo\\TIME_PERIOD",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "freq,unit,s_adj,indic,geo\\TIME_PERIOD",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2024-05 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2024-05 ",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2024-06 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2024-06 ",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2024-07 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2024-07 ",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2024-08 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2024-08 ",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2024-09 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2024-09 ",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2024-10 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2024-10 ",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2024-11 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2024-11 ",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2024-12 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2024-12 ",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2025-01 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2025-01 ",
											"type": "String",
											"physicalType": "String"
										}
									},
									{
										"source": {
											"name": "2025-02 ",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "2025-02 ",
											"type": "String",
											"physicalType": "String"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "Web_Eurostat_Inflation",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "External_Inflation_Csv",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Arch"
				},
				"annotations": [],
				"lastPublishTime": "2025-03-26T08:44:54Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Web_Eurostat_Inflation')]",
				"[concat(variables('workspaceId'), '/datasets/External_Inflation_Csv')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Load To Gold')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Dimensions",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "D_DIM_SQL",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 2,
								"spark.dynamicAllocation.maxExecutors": 2
							},
							"driverSize": "Small",
							"numExecutors": 2,
							"authentication": {
								"type": "MSI"
							}
						}
					},
					{
						"name": "Dates",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "Dimensions",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "D_DATES_PY",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 2,
								"spark.dynamicAllocation.maxExecutors": 2
							},
							"driverSize": "Small",
							"numExecutors": 2,
							"authentication": {
								"type": "MSI"
							}
						}
					},
					{
						"name": "Planning Book",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "Dates",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "F_PLANNING_BOOK_PY",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 2,
								"spark.dynamicAllocation.maxExecutors": 2
							},
							"driverSize": "Small",
							"numExecutors": 2,
							"authentication": {
								"type": "MSI"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Gold"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/D_DIM_SQL')]",
				"[concat(variables('workspaceId'), '/bigDataPools/sparkpool32')]",
				"[concat(variables('workspaceId'), '/notebooks/D_DATES_PY')]",
				"[concat(variables('workspaceId'), '/notebooks/F_PLANNING_BOOK_PY')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Orchestrator Pipeline')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Extract Erp Data",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "Extract Erp Data",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "Extract MinIO Data",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "Extract Erp Data",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "Extract MinIO Data",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "Load To Gold",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "Transform In Silver",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "Load To Gold",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "Transform In Silver",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "Extract MinIO Data",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "Transform In Silver",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Extract Erp Data')]",
				"[concat(variables('workspaceId'), '/pipelines/Extract MinIO Data')]",
				"[concat(variables('workspaceId'), '/pipelines/Load To Gold')]",
				"[concat(variables('workspaceId'), '/pipelines/Transform In Silver')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Transform In Silver')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "D_CUSTOMERS",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "D_CUSTOMERS_LOAD_SQL",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 1,
								"spark.dynamicAllocation.maxExecutors": 1
							},
							"driverSize": "Small",
							"numExecutors": 1,
							"authentication": {
								"type": "MSI"
							}
						}
					},
					{
						"name": "D_PRODUCTS",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "D_CUSTOMERS",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "D_PRODUCT_LOAD_SQL",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 1,
								"spark.dynamicAllocation.maxExecutors": 1
							},
							"driverSize": "Small",
							"numExecutors": 1,
							"authentication": {
								"type": "MSI"
							}
						}
					},
					{
						"name": "F_FORECAST",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "D_PRODUCTS",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "F_FORCAST_LOAD_SQL",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 1,
								"spark.dynamicAllocation.maxExecutors": 1
							},
							"driverSize": "Small",
							"numExecutors": 1,
							"authentication": {
								"type": "MSI"
							}
						}
					},
					{
						"name": "F_SALES",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "F_FORECAST",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "F_SALES_LOAD_SQL",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": null,
								"spark.dynamicAllocation.minExecutors": 1,
								"spark.dynamicAllocation.maxExecutors": 1
							},
							"driverSize": "Small",
							"numExecutors": 1,
							"authentication": {
								"type": "MSI"
							}
						}
					},
					{
						"name": "F_POS",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "F_SALES",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "F_POS_LOAD_SQL",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 1,
								"spark.dynamicAllocation.maxExecutors": 1
							},
							"driverSize": "Small",
							"numExecutors": 1,
							"authentication": {
								"type": "MSI"
							}
						}
					},
					{
						"name": "F_WH",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "F_POS",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "F_WH_DATA_LOAD_SQL",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "sparkpool32",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": false,
								"spark.dynamicAllocation.minExecutors": 1,
								"spark.dynamicAllocation.maxExecutors": 1
							},
							"driverSize": "Small",
							"numExecutors": 1,
							"authentication": {
								"type": "MSI"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Silver"
				},
				"annotations": [],
				"lastPublishTime": "2025-04-02T06:40:26Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/D_CUSTOMERS_LOAD_SQL')]",
				"[concat(variables('workspaceId'), '/bigDataPools/sparkpool32')]",
				"[concat(variables('workspaceId'), '/notebooks/D_PRODUCT_LOAD_SQL')]",
				"[concat(variables('workspaceId'), '/notebooks/F_FORCAST_LOAD_SQL')]",
				"[concat(variables('workspaceId'), '/notebooks/F_SALES_LOAD_SQL')]",
				"[concat(variables('workspaceId'), '/notebooks/F_POS_LOAD_SQL')]",
				"[concat(variables('workspaceId'), '/notebooks/F_WH_DATA_LOAD_SQL')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Bronze_Csv')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "mrgbigpharma-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"filename": {
						"type": "string"
					}
				},
				"folder": {
					"name": "Targets_Bronze"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().filename",
							"type": "Expression"
						},
						"folderPath": "Erp",
						"fileSystem": "bronze"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/mrgbigpharma-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Bronze_Log_Parquet')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "mrgbigpharma-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"folder": {
					"name": "Sources_Bronze"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "logs.parquet",
						"folderPath": "Erp/logs",
						"fileSystem": "bronze"
					},
					"compressionCodec": "snappy"
				},
				"schema": [
					{
						"name": "table_name",
						"type": "UTF8"
					},
					{
						"name": "create_date",
						"type": "INT96"
					},
					{
						"name": "update_date",
						"type": "INT96"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/mrgbigpharma-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Bronze_Parquet')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "mrgbigpharma-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"filename": {
						"type": "string"
					},
					"foldername": {
						"type": "string"
					}
				},
				"folder": {
					"name": "Targets_Bronze"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().filename",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@concat('Erp/',dataset().foldername)",
							"type": "Expression"
						},
						"fileSystem": "bronze"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/mrgbigpharma-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ERP_DATA_LOCATION')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "mrgbigpharma-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"TblName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().TblName",
							"type": "Expression"
						},
						"folderPath": "Erp",
						"fileSystem": "bronze"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/mrgbigpharma-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/External_Inflation_Csv')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "mrgbigpharma-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"folder": {
					"name": "Targets_Bronze"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "inflation.csv",
						"folderPath": "ExternalStatistics",
						"fileSystem": "bronze"
					},
					"columnDelimiter": ";",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/mrgbigpharma-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MinIoDataDistributors')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "MinIoS3",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AmazonS3CompatibleLocation",
						"bucketName": "distributors",
						"fileName": "part-00000-b20e9098-7b48-48f2-888f-57de2602203c.c000.csv"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/MinIoS3')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MySql_Erp_Dynamic_Load')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "MySqlErp",
					"type": "LinkedServiceReference",
					"parameters": {
						"User": "serwer296707_pharma",
						"Database": "serwer296707_pharma",
						"Server": "sql133.lh.pl"
					}
				},
				"folder": {
					"name": "Sources_Bronze"
				},
				"annotations": [],
				"type": "MySqlTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/MySqlErp')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MySql_Erp_List_Tables')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "MySqlErp",
					"type": "LinkedServiceReference",
					"parameters": {
						"User": "serwer296707_pharma",
						"Database": "serwer296707_pharma",
						"Server": "sql133.lh.pl"
					}
				},
				"folder": {
					"name": "Sources_Bronze"
				},
				"annotations": [],
				"type": "MySqlTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/MySqlErp')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SinkBronzeDistributors')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "mrgbigpharma-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"FileName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().FileName",
							"type": "Expression"
						},
						"folderPath": "MinIoDistributors",
						"fileSystem": "bronze"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/mrgbigpharma-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Web_Eurostat_Inflation')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "eceuropaeu_inflation",
					"type": "LinkedServiceReference"
				},
				"folder": {
					"name": "Sources_Bronze"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "HttpServerLocation"
					},
					"columnDelimiter": "\t",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "freq,unit,s_adj,indic,geo\\TIME_PERIOD",
						"type": "String"
					},
					{
						"name": "2024-05 ",
						"type": "String"
					},
					{
						"name": "2024-06 ",
						"type": "String"
					},
					{
						"name": "2024-07 ",
						"type": "String"
					},
					{
						"name": "2024-08 ",
						"type": "String"
					},
					{
						"name": "2024-09 ",
						"type": "String"
					},
					{
						"name": "2024-10 ",
						"type": "String"
					},
					{
						"name": "2024-11 ",
						"type": "String"
					},
					{
						"name": "2024-12 ",
						"type": "String"
					},
					{
						"name": "2025-01 ",
						"type": "String"
					},
					{
						"name": "2025-02 ",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/eceuropaeu_inflation')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AmazonS3Compatible2')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AmazonS3Compatible",
				"typeProperties": {
					"serviceUrl": "http://20.215.33.25:9000",
					"accessKeyId": "[parameters('AmazonS3Compatible2_properties_typeProperties_accessKeyId')]",
					"secretAccessKey": {
						"type": "SecureString",
						"value": "[parameters('AmazonS3Compatible2_secretAccessKey')]"
					},
					"forcePathStyle": true
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureKeyVault')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('AzureKeyVault_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MinIoS3')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AmazonS3Compatible",
				"typeProperties": {
					"serviceUrl": "http://20.215.33.25:9000",
					"accessKeyId": "[parameters('MinIoS3_properties_typeProperties_accessKeyId')]",
					"secretAccessKey": {
						"type": "SecureString",
						"value": "[parameters('MinIoS3_secretAccessKey')]"
					},
					"forcePathStyle": true
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MySqlErp')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"User": {
						"type": "String",
						"defaultValue": "serwer296707_pharma"
					},
					"Database": {
						"type": "String",
						"defaultValue": "serwer296707_pharma"
					},
					"Server": {
						"type": "String",
						"defaultValue": "sql133.lh.pl"
					}
				},
				"annotations": [],
				"type": "MySql",
				"typeProperties": {
					"server": "[parameters('MySqlErp_properties_typeProperties_server')]",
					"port": 3306,
					"database": "[parameters('MySqlErp_properties_typeProperties_database')]",
					"username": "[parameters('MySqlErp_properties_typeProperties_username')]",
					"sslMode": 1,
					"useSystemTrustStore": 0,
					"password": {
						"type": "AzureKeyVaultSecret",
						"store": {
							"referenceName": "MySqlPassword",
							"type": "LinkedServiceReference"
						},
						"secretName": "mysqlpassword"
					},
					"driverVersion": "v2"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/linkedServices/MySqlPassword')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MySqlPassword')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('MySqlPassword_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/S3MinIO')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AmazonS3",
				"typeProperties": {
					"serviceUrl": "http://20.215.33.25:9000",
					"accessKeyId": "[parameters('S3MinIO_properties_typeProperties_accessKeyId')]",
					"secretAccessKey": {
						"type": "SecureString",
						"value": "[parameters('S3MinIO_secretAccessKey')]"
					},
					"authenticationType": "AccessKey"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/eceuropaeu_inflation')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "HttpServer",
				"typeProperties": {
					"url": "[parameters('eceuropaeu_inflation_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/mrgbigpharma-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('mrgbigpharma-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/mrgbigpharma-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('mrgbigpharma-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n    count(*)\nFROM\n    OPENROWSET(\n        BULK 'https://bigpharma.dfs.core.windows.net/silver/d_customers/',\n        FORMAT = 'DELTA'\n    ) AS [result]\n276\n\n-- This is auto-generated code\n--44 \n\nSELECT\n    count(*)\nFROM\n    OPENROWSET(\n        BULK 'https://bigpharma.dfs.core.windows.net/silver/d_products/',\n        FORMAT = 'DELTA'\n    ) AS [result]\n\n--5346\n\nSELECT\n    count(*)\nFROM\n    OPENROWSET(\n        BULK 'https://bigpharma.dfs.core.windows.net/silver/f_forecast/',\n        FORMAT = 'DELTA'\n    ) AS [result]\n43604\n\nSELECT\n    count(*)\nFROM\n    OPENROWSET(\n        BULK 'https://bigpharma.dfs.core.windows.net/silver/f_pos_data/',\n        FORMAT = 'DELTA'\n    ) AS [result]  \n\n45144\n\nSELECT\n    count(*)\nFROM\n    OPENROWSET(\n        BULK 'https://bigpharma.dfs.core.windows.net/silver/f_sales/',\n        FORMAT = 'DELTA'\n    ) AS [result]  \n\n\n\n45144\n\nSELECT\n    count(*)\nFROM\n    OPENROWSET(\n        BULK 'https://bigpharma.dfs.core.windows.net/silver/f_wh_data/',\n        FORMAT = 'DELTA'\n    ) AS [result]  \n\n\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/D_CUSTOMERS_LOAD_SQL')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load_Silver"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "fa97b0f8-8054-411d-8484-8e105ac20cd8"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_sparksql",
						"display_name": "sql"
					},
					"language_info": {
						"name": "sql"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/825011b4-60a2-4e32-a6f1-221c4bc009ef/resourceGroups/lakehouse/providers/Microsoft.Synapse/workspaces/mrgbigpharma/bigDataPools/sparkpool32",
						"name": "sparkpool32",
						"type": "Spark",
						"endpoint": "https://mrgbigpharma.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"-- test D_CUSTOMERS_LOAD_SQL\n",
							"\n",
							"CREATE DATABASE IF NOT EXISTS silver;\n",
							"\n",
							"-- 1. Register bronze_customers as a temporary view\n",
							"CREATE OR REPLACE TEMP VIEW bronze_customers\n",
							"USING parquet\n",
							"OPTIONS (\n",
							"  path 'abfss://bronze@bigpharma.dfs.core.windows.net/Erp/customers/'\n",
							");\n",
							"\n",
							"-- 2. Register bronze_countries as a temporary view\n",
							"CREATE OR REPLACE TEMP VIEW bronze_countries\n",
							"USING parquet\n",
							"OPTIONS (\n",
							"  path 'abfss://bronze@bigpharma.dfs.core.windows.net/Erp/countries/'\n",
							");\n",
							"\n",
							"-- 3. Prepare data – JOIN + select the most recent by customer_id\n",
							"--CREATE OR REPLACE TEMP VIEW new_bronze_d_customers AS\n",
							"--SELECT \n",
							"--    c.customer_id,\n",
							"--    c.country_id,\n",
							"--    c.company_name,\n",
							"--    c.address,\n",
							"--    c.city,\n",
							"--    co.region_description,\n",
							"--    co.country,\n",
							"--    co.cluster,\n",
							"--    c.update_date as customer_update_date,\n",
							"--    co.update_date as country_update_date\n",
							"--FROM bronze_customers c\n",
							"--JOIN bronze_countries co\n",
							"--  ON c.country_id = co.country_id;\n",
							"\n",
							"\n",
							"\n",
							"CREATE OR REPLACE TEMP VIEW new_bronze_d_customers AS\n",
							"\n",
							"WITH latest_customers AS (\n",
							"    SELECT *,\n",
							"           MAX(update_date) OVER (PARTITION BY customer_id) AS max_customer_update\n",
							"    FROM bronze_customers\n",
							"),\n",
							"filtered_customers AS (\n",
							"    SELECT *\n",
							"    FROM latest_customers\n",
							"    WHERE update_date = max_customer_update\n",
							"),\n",
							"\n",
							"latest_countries AS (\n",
							"    SELECT *,\n",
							"           MAX(update_date) OVER (PARTITION BY country_id) AS max_country_update\n",
							"    FROM bronze_countries\n",
							"),\n",
							"filtered_countries AS (\n",
							"    SELECT *\n",
							"    FROM latest_countries\n",
							"    WHERE update_date = max_country_update\n",
							")\n",
							"\n",
							"SELECT \n",
							"    c.customer_id,\n",
							"    c.country_id,\n",
							"    c.company_name,\n",
							"    c.address,\n",
							"    c.city,\n",
							"    co.region_description,\n",
							"    co.country,\n",
							"    co.cluster,\n",
							"    c.update_date AS customer_update_date,\n",
							"    co.update_date AS country_update_date\n",
							"FROM filtered_customers c\n",
							"JOIN filtered_countries co\n",
							"  ON c.country_id = co.country_id;\n",
							"\n",
							"\n",
							"\n",
							"\n",
							"-- 4. Create the target table as Delta Lake (if it does not exist)\n",
							"CREATE TABLE IF NOT EXISTS silver.d_customers\n",
							"USING delta\n",
							"LOCATION 'abfss://silver@bigpharma.dfs.core.windows.net/d_customers'\n",
							"AS\n",
							"SELECT * FROM new_bronze_d_customers\n",
							"WHERE 1 = 0;\n",
							"\n",
							"-- 5. Filter new or updated records\n",
							"CREATE OR REPLACE TEMP VIEW filter_bronze_d_customers AS\n",
							"SELECT * FROM new_bronze_d_customers n \n",
							"WHERE NOT EXISTS (\n",
							"  SELECT 1 FROM silver.d_customers s \n",
							"  WHERE s.customer_id = n.customer_id\n",
							"    AND s.country_id = n.country_id\n",
							"    AND s.customer_update_date = n.customer_update_date\n",
							"    AND s.country_update_date = n.country_update_date\n",
							");\n",
							"\n",
							"-- 6. MERGE (UPSERT)\n",
							"MERGE INTO silver.d_customers AS target\n",
							"USING filter_bronze_d_customers AS source\n",
							"ON target.customer_id = source.customer_id\n",
							"\n",
							"WHEN MATCHED THEN\n",
							"  UPDATE SET\n",
							"    country_id = source.country_id,\n",
							"    company_name = source.company_name,\n",
							"    address = source.address,\n",
							"    city = source.city,\n",
							"    region_description = source.region_description,\n",
							"    country = source.country,\n",
							"    cluster = source.cluster,\n",
							"    customer_update_date = source.customer_update_date,\n",
							"    country_update_date = source.country_update_date\n",
							"\n",
							"WHEN NOT MATCHED THEN\n",
							"  INSERT (\n",
							"    customer_id,\n",
							"    country_id,\n",
							"    company_name,\n",
							"    address,\n",
							"    city,\n",
							"    region_description,\n",
							"    country,\n",
							"    cluster,\n",
							"    customer_update_date,\n",
							"    country_update_date\n",
							"  )\n",
							"  VALUES (\n",
							"    source.customer_id,\n",
							"    source.country_id,\n",
							"    source.company_name,\n",
							"    source.address,\n",
							"    source.city,\n",
							"    source.region_description,\n",
							"    source.country,\n",
							"    source.cluster,\n",
							"    source.customer_update_date,\n",
							"    source.country_update_date\n",
							"  );\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/D_DATES_PY')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load Gold"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "14cd35ad-be85-48a5-aa6f-b6dd28ab0a2a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/825011b4-60a2-4e32-a6f1-221c4bc009ef/resourceGroups/lakehouse/providers/Microsoft.Synapse/workspaces/mrgbigpharma/bigDataPools/sparkpool32",
						"name": "sparkpool32",
						"type": "Spark",
						"endpoint": "https://mrgbigpharma.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from pyspark.sql.functions import (\n",
							"    col, lit, year, month, quarter, weekofyear, dayofmonth,\n",
							"    dayofweek, dayofyear, date_format, current_timestamp, when, concat_ws\n",
							")\n",
							"from datetime import datetime, timedelta\n",
							"import pandas as pd\n",
							"\n",
							"# Define the date range for the calendar table\n",
							"start_year = 2020\n",
							"end_year = 2025\n",
							"\n",
							"# Create a list of dates from start_date to end_date using pandas\n",
							"start_date = datetime(start_year, 1, 1)\n",
							"end_date = datetime(end_year, 12, 31)\n",
							"date_range = pd.date_range(start=start_date, end=end_date).to_frame(index=False, name=\"Date\")\n",
							"\n",
							"# Convert the pandas DataFrame to a Spark DataFrame\n",
							"df = spark.createDataFrame(date_range)\n",
							"\n",
							"# Add calendar-related columns to enrich the date dimension\n",
							"df = df.withColumn(\"Year\", year(\"Date\")) \\\n",
							"       .withColumn(\"Month\", month(\"Date\")) \\\n",
							"       .withColumn(\"Quarter\", quarter(\"Date\")) \\\n",
							"       .withColumn(\"WeekOfYear\", weekofyear(\"Date\")) \\\n",
							"       .withColumn(\"Day\", dayofmonth(\"Date\")) \\\n",
							"       .withColumn(\"DayOfWeek\", dayofweek(\"Date\")) \\\n",
							"       .withColumn(\"DayOfYear\", dayofyear(\"Date\")) \\\n",
							"       .withColumn(\"DayName\", date_format(\"Date\", \"EEEE\")) \\\n",
							"       .withColumn(\"MonthName\", date_format(\"Date\", \"MMMM\")) \\\n",
							"       .withColumn(\"NowMonth\", month(current_timestamp())) \\\n",
							"       .withColumn(\"YTD_BTG\", when(col(\"Month\") < col(\"NowMonth\"), \"YTD\").otherwise(\"BTG\")) \\\n",
							"       .withColumn(\"FY\", lit(\"FY\")) \\\n",
							"       .withColumn(\"QuarterStr\", concat_ws(\"\", lit(\"Q\"), col(\"Quarter\").cast(\"string\"))) \\\n",
							"       .withColumn(\"KeyYearMonth\", concat_ws(\"\", col(\"Year\").cast(\"string\"), col(\"Month\").cast(\"string\"))) \\\n",
							"       .withColumn(\"KeyYearQuarter\", concat_ws(\"\", col(\"Year\").cast(\"string\"), col(\"QuarterStr\"))) \\\n",
							"       .withColumn(\"KeyYearYTDBTG\", concat_ws(\"\", col(\"Year\").cast(\"string\"), col(\"YTD_BTG\"))) \\\n",
							"       .withColumn(\"KeyYearFY\", concat_ws(\"\", col(\"Year\").cast(\"string\"), col(\"FY\")))\n",
							"\n",
							"\n",
							"# Remove unused composite key columns\n",
							"df = df.drop(\"KeyYearMonth\", \"KeyYearQuarter\", \"KeyYearYTDBTG\", \"KeyYearFY\")\n",
							"\n",
							"# Optional: reorder columns to desired output format\n",
							"columns_order = [\"Year\", \"Quarter\", \"Month\", \"Date\", \"YTD_BTG\"]\n",
							"\n",
							"df = df.select(*columns_order)\n",
							"\n",
							"# Save the resulting date dimension to a Delta Lake table in Azure Data Lake Storage\n",
							"df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").format(\"delta\").save(\"abfss://gold@bigpharma.dfs.core.windows.net/d_dates\")\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/D_DIM_SQL')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load Gold"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "b9b2d180-3362-46f2-a3b4-137baa4857c0"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_sparksql",
						"display_name": "sql"
					},
					"language_info": {
						"name": "sql"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"CREATE DATABASE IF NOT EXISTS gold;\n",
							"\n",
							"-- Create views on Silver tables\n",
							"CREATE OR REPLACE VIEW silver_d_products AS\n",
							"SELECT * FROM delta.`abfss://silver@bigpharma.dfs.core.windows.net/d_products`;\n",
							"\n",
							"CREATE OR REPLACE VIEW silver_d_regions AS\n",
							"SELECT * FROM delta.`abfss://silver@bigpharma.dfs.core.windows.net/d_customers`;\n",
							"\n",
							"-- Create tables in the Gold layer\n",
							"CREATE TABLE IF NOT EXISTS gold.d_products\n",
							"USING DELTA\n",
							"LOCATION 'abfss://gold@bigpharma.dfs.core.windows.net/d_products'\n",
							"AS\n",
							"SELECT \n",
							"  product_id AS IdProduct,\n",
							"  product_name AS Name,\n",
							"  brand_name AS Brand,\n",
							"  sub_brand_name AS SubBrand,\n",
							"  category_name AS Category \n",
							"FROM silver_d_products\n",
							"WHERE 1 = 0;\n",
							"\n",
							"CREATE TABLE IF NOT EXISTS gold.d_regions\n",
							"USING DELTA\n",
							"LOCATION 'abfss://gold@bigpharma.dfs.core.windows.net/d_customers'\n",
							"AS\n",
							"SELECT \n",
							"  country_id AS IDCountry,\n",
							"  cluster AS Claster,\n",
							"  region_description AS Region,\n",
							"  country AS Country\n",
							"FROM silver_d_regions\n",
							"WHERE 1 = 0;\n",
							"\n",
							"-- Rename columns in the d_products table and write to Gold layer\n",
							"INSERT OVERWRITE TABLE gold.d_products\n",
							"SELECT \n",
							"  product_id AS IdProduct,\n",
							"  product_name AS Name,\n",
							"  brand_name AS Brand,\n",
							"  sub_brand_name AS SubBrand,\n",
							"  category_name AS Category\n",
							"FROM silver_d_products;\n",
							"\n",
							"-- Remove duplicates in the d_regions table and write to the Gold table\n",
							"INSERT OVERWRITE TABLE gold.d_regions\n",
							"SELECT DISTINCT \n",
							"  country_id AS IDCountry,\n",
							"  cluster AS Claster,\n",
							"  region_description AS Region,\n",
							"  country AS Country\n",
							"FROM silver_d_regions;\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/D_PRODUCT_LOAD_SQL')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load_Silver"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "5917df23-5b1b-48ba-8525-427b04230b75"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_sparksql",
						"display_name": "sql"
					},
					"language_info": {
						"name": "sql"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"CREATE DATABASE IF NOT EXISTS silver;\n",
							"\n",
							"-- ============================================\n",
							"-- 1. Register data from Bronze as a temporary view\n",
							"-- ============================================\n",
							"\n",
							"CREATE OR REPLACE TEMP VIEW bronze_products\n",
							"USING parquet\n",
							"OPTIONS (\n",
							"  path 'abfss://bronze@bigpharma.dfs.core.windows.net/Erp/products'\n",
							");\n",
							"\n",
							"-- ============================================\n",
							"-- 2. Select the most recent data by update_date\n",
							"-- ============================================\n",
							"\n",
							"--CREATE OR REPLACE TEMP VIEW new_d_products AS\n",
							"--SELECT \n",
							"--    product_id,\n",
							"--    product_name,\n",
							"--    brand_name,\n",
							"--    sub_brand_name,\n",
							"--    category_name,\n",
							"--    update_date AS product_update_date\n",
							"--FROM bronze_products;\n",
							"\n",
							"CREATE OR REPLACE TEMP VIEW new_d_products AS\n",
							"WITH products_with_max_date AS (\n",
							"    SELECT \n",
							"        product_id,\n",
							"        product_name,\n",
							"        brand_name,\n",
							"        sub_brand_name,\n",
							"        category_name,\n",
							"        update_date AS product_update_date,\n",
							"        MAX(update_date) OVER (PARTITION BY product_id) AS max_update_date\n",
							"    FROM bronze_products\n",
							")\n",
							"SELECT \n",
							"    product_id,\n",
							"    product_name,\n",
							"    brand_name,\n",
							"    sub_brand_name,\n",
							"    category_name,\n",
							"    product_update_date\n",
							"FROM products_with_max_date\n",
							"WHERE product_update_date = max_update_date;\n",
							"\n",
							"-- ============================================\n",
							"-- 3. Create the target (Silver) table if it does not exist\n",
							"-- ============================================\n",
							"\n",
							"CREATE TABLE IF NOT EXISTS silver.d_products\n",
							"USING delta\n",
							"LOCATION 'abfss://silver@bigpharma.dfs.core.windows.net/d_products'\n",
							"AS\n",
							"SELECT * FROM new_d_products\n",
							"WHERE 1 = 0;\n",
							"\n",
							"-- Filter new or updated records\n",
							"CREATE OR REPLACE TEMP VIEW filter_d_products AS\n",
							"SELECT * FROM new_d_products n \n",
							"WHERE NOT EXISTS (\n",
							"  SELECT 1 FROM silver.d_products s \n",
							"  WHERE s.product_id = n.product_id \n",
							"    AND s.product_update_date = n.product_update_date\n",
							");\n",
							"\n",
							"-- ============================================\n",
							"-- 4. MERGE INTO (UPSERT) data into the Silver table\n",
							"-- ============================================\n",
							"\n",
							"MERGE INTO silver.d_products AS target\n",
							"USING filter_d_products AS source\n",
							"ON target.product_id = source.product_id\n",
							"\n",
							"WHEN MATCHED THEN\n",
							"  UPDATE SET\n",
							"    target.product_name = source.product_name,\n",
							"    target.brand_name = source.brand_name,\n",
							"    target.sub_brand_name = source.sub_brand_name,\n",
							"    target.category_name = source.category_name,\n",
							"    target.product_update_date = source.product_update_date\n",
							"\n",
							"WHEN NOT MATCHED THEN\n",
							"  INSERT (\n",
							"    product_id,\n",
							"    product_name,\n",
							"    brand_name,\n",
							"    sub_brand_name,\n",
							"    category_name,\n",
							"    product_update_date\n",
							"  )\n",
							"  VALUES (\n",
							"    source.product_id,\n",
							"    source.product_name,\n",
							"    source.brand_name,\n",
							"    source.sub_brand_name,\n",
							"    source.category_name,\n",
							"    source.product_update_date\n",
							"  );\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/F_FORCAST_LOAD_SQL')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load_Silver"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "43f7e592-c61b-43ea-94ac-a5e4e3e05539"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_sparksql",
						"display_name": "sql"
					},
					"language_info": {
						"name": "sql"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"CREATE DATABASE IF NOT EXISTS silver;\n",
							"\n",
							"-- ============================================\n",
							"-- 1. Load data from the Bronze layer as a temporary view\n",
							"-- ============================================\n",
							"CREATE OR REPLACE TEMP VIEW bronze_forecast\n",
							"USING parquet\n",
							"OPTIONS (\n",
							"  path 'abfss://bronze@bigpharma.dfs.core.windows.net/Erp/forecast_details'\n",
							");\n",
							"\n",
							"-- ============================================\n",
							"-- 2. Aggregate the most recent data at the monthly level\n",
							"-- ============================================\n",
							"--CREATE OR REPLACE TEMP VIEW aggregated_forecast AS\n",
							"--SELECT \n",
							"--    product_id,\n",
							"--    country_id,\n",
							"--    max(update_date) as forecast_update_date,\n",
							"--    TRUNC(forecast_date, \"MM\") AS forecast_date,\n",
							"--    TRUNC(forecast_snapshot, \"MM\") AS forecast_snapshot,\n",
							"--    \n",
							"--    SUM(quantity) AS quantity,\n",
							"--    SUM(whrs_sell_in_quantity) AS whrs_sell_in_quantity,\n",
							"--    SUM(whrs_open_quantity) AS whrs_open_quantity,\n",
							"--    SUM(whrs_end_quantity) AS whrs_end_quantity,\n",
							"    \n",
							"--    SUM(pos_sell_out_quantity) AS pos_sell_out_quantity,\n",
							"--    SUM(pos_open_quantity) AS pos_open_quantity,\n",
							"--    SUM(pos_end_quantity) AS pos_end_quantity,\n",
							"    \n",
							"--    ROUND(SUM(quantity * unit_price), 2) AS amount,\n",
							"--    ROUND(SUM(whrs_sell_in_quantity * unit_price), 2) AS whrs_sell_in_amount,\n",
							"--    ROUND(SUM(whrs_open_quantity * unit_price), 2) AS whrs_open_amount,\n",
							"--    ROUND(SUM(whrs_end_quantity * unit_price), 2) AS whrs_end_amount,\n",
							"    \n",
							"--    ROUND(SUM(pos_sell_out_quantity * unit_price), 2) AS pos_sell_out_amount,\n",
							"--    ROUND(SUM(pos_open_quantity * unit_price), 2) AS pos_open_amount,\n",
							"--    ROUND(SUM(pos_end_quantity * unit_price), 2) AS pos_end_amount,\n",
							"    \n",
							"--    ROUND(SUM(quantity * unit_price) / NULLIF(SUM(quantity), 0), 2) AS unit_price\n",
							"--FROM  bronze_forecast\n",
							"--GROUP BY product_id, country_id, TRUNC(forecast_date, 'MM'), TRUNC(forecast_snapshot, 'MM');\n",
							"\n",
							"\n",
							"CREATE OR REPLACE TEMP VIEW aggregated_forecast AS\n",
							"WITH forecast_with_max_date AS (\n",
							"    SELECT \n",
							"        product_id,\n",
							"        country_id,\n",
							"        update_date,\n",
							"        forecast_date,\n",
							"        forecast_snapshot,\n",
							"        quantity,\n",
							"        whrs_sell_in_quantity,\n",
							"        whrs_open_quantity,\n",
							"        whrs_end_quantity,\n",
							"        pos_sell_out_quantity,\n",
							"        pos_open_quantity,\n",
							"        pos_end_quantity,\n",
							"        unit_price,\n",
							"        MAX(update_date) OVER (PARTITION BY product_id, country_id, TRUNC(forecast_date, 'MM'), TRUNC(forecast_snapshot, 'MM')) AS max_update_date\n",
							"    FROM bronze_forecast\n",
							")\n",
							"SELECT \n",
							"    product_id,\n",
							"    country_id,\n",
							"    MAX(update_date) AS forecast_update_date,\n",
							"    TRUNC(forecast_date, \"MM\") AS forecast_date,\n",
							"    TRUNC(forecast_snapshot, \"MM\") AS forecast_snapshot,\n",
							"    \n",
							"    SUM(quantity) AS quantity,\n",
							"    SUM(whrs_sell_in_quantity) AS whrs_sell_in_quantity,\n",
							"    SUM(whrs_open_quantity) AS whrs_open_quantity,\n",
							"    SUM(whrs_end_quantity) AS whrs_end_quantity,\n",
							"    \n",
							"    SUM(pos_sell_out_quantity) AS pos_sell_out_quantity,\n",
							"    SUM(pos_open_quantity) AS pos_open_quantity,\n",
							"    SUM(pos_end_quantity) AS pos_end_quantity,\n",
							"    \n",
							"    ROUND(SUM(quantity * unit_price), 2) AS amount,\n",
							"    ROUND(SUM(whrs_sell_in_quantity * unit_price), 2) AS whrs_sell_in_amount,\n",
							"    ROUND(SUM(whrs_open_quantity * unit_price), 2) AS whrs_open_amount,\n",
							"    ROUND(SUM(whrs_end_quantity * unit_price), 2) AS whrs_end_amount,\n",
							"    \n",
							"    ROUND(SUM(pos_sell_out_quantity * unit_price), 2) AS pos_sell_out_amount,\n",
							"    ROUND(SUM(pos_open_quantity * unit_price), 2) AS pos_open_amount,\n",
							"    ROUND(SUM(pos_end_quantity * unit_price), 2) AS pos_end_amount,\n",
							"    \n",
							"    ROUND(SUM(quantity * unit_price) / NULLIF(SUM(quantity), 0), 2) AS unit_price\n",
							"FROM forecast_with_max_date\n",
							"WHERE update_date = max_update_date\n",
							"GROUP BY product_id, country_id, TRUNC(forecast_date, 'MM'), TRUNC(forecast_snapshot, 'MM');\n",
							"\n",
							"\n",
							"\n",
							"-- ============================================\n",
							"-- 3. Create the Silver table if it does not exist\n",
							"-- ============================================\n",
							"CREATE TABLE IF NOT EXISTS silver.f_forecast\n",
							"USING delta\n",
							"LOCATION 'abfss://silver@bigpharma.dfs.core.windows.net/f_forecast'\n",
							"AS\n",
							"SELECT * FROM aggregated_forecast\n",
							"WHERE 1 = 0;\n",
							"\n",
							"-- Filter new or updated records\n",
							"CREATE OR REPLACE TEMP VIEW filter_aggregated_forecast AS\n",
							"SELECT * from aggregated_forecast n \n",
							"where  NOT EXISTS (select product_id From silver.f_forecast s \n",
							"                    where s.product_id = n.product_id \n",
							"                      and s.country_id = n.country_id\n",
							"                      and s.forecast_update_date = n.forecast_update_date\n",
							"                      and s.forecast_date = n.forecast_date\n",
							"                      and s.forecast_snapshot = n.forecast_snapshot);\n",
							"\n",
							"-- ============================================\n",
							"-- 4. Perform MERGE INTO to update or insert new data\n",
							"-- ============================================\n",
							"\n",
							"MERGE INTO silver.f_forecast AS target\n",
							"USING filter_aggregated_forecast AS source\n",
							"ON target.product_id = source.product_id\n",
							"   AND target.country_id = source.country_id\n",
							"   AND target.forecast_date = source.forecast_date\n",
							"   AND target.forecast_snapshot = source.forecast_snapshot\n",
							"\n",
							"WHEN MATCHED THEN\n",
							"  UPDATE SET\n",
							"    target.quantity = source.quantity,\n",
							"    target.whrs_sell_in_quantity = source.whrs_sell_in_quantity,\n",
							"    target.whrs_open_quantity = source.whrs_open_quantity,\n",
							"    target.whrs_end_quantity = source.whrs_end_quantity,\n",
							"    \n",
							"    target.pos_sell_out_quantity = source.pos_sell_out_quantity,\n",
							"    target.pos_open_quantity = source.pos_open_quantity,\n",
							"    target.pos_end_quantity = source.pos_end_quantity,\n",
							"    \n",
							"    target.amount = source.amount,\n",
							"    target.whrs_sell_in_amount = source.whrs_sell_in_amount,\n",
							"    target.whrs_open_amount = source.whrs_open_amount,\n",
							"    target.whrs_end_amount = source.whrs_end_amount,\n",
							"    \n",
							"    target.pos_sell_out_amount = source.pos_sell_out_amount,\n",
							"    target.pos_open_amount = source.pos_open_amount,\n",
							"    target.pos_end_amount = source.pos_end_amount,\n",
							"    \n",
							"    target.unit_price = source.unit_price,\n",
							"    target.forecast_update_date = source.forecast_update_date\n",
							"\n",
							"WHEN NOT MATCHED THEN\n",
							"  INSERT (\n",
							"    product_id, country_id, forecast_date, forecast_snapshot,\n",
							"    quantity, whrs_sell_in_quantity, whrs_open_quantity, whrs_end_quantity,\n",
							"    pos_sell_out_quantity, pos_open_quantity, pos_end_quantity,\n",
							"    amount, whrs_sell_in_amount, whrs_open_amount, whrs_end_amount,\n",
							"    pos_sell_out_amount, pos_open_amount, pos_end_amount, unit_price, forecast_update_date\n",
							"  )\n",
							"  VALUES (\n",
							"    source.product_id, source.country_id, source.forecast_date, source.forecast_snapshot,\n",
							"    source.quantity, source.whrs_sell_in_quantity, source.whrs_open_quantity, source.whrs_end_quantity,\n",
							"    source.pos_sell_out_quantity, source.pos_open_quantity, source.pos_end_quantity,\n",
							"    source.amount, source.whrs_sell_in_amount, source.whrs_open_amount, source.whrs_end_amount,\n",
							"    source.pos_sell_out_amount, source.pos_open_amount, source.pos_end_amount, source.unit_price, source.forecast_update_date\n",
							"  );\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/F_PLANNING_BOOK_PY')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load Gold"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "24263fa7-6520-430f-aef9-2d7fd7b65500"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/825011b4-60a2-4e32-a6f1-221c4bc009ef/resourceGroups/lakehouse/providers/Microsoft.Synapse/workspaces/mrgbigpharma/bigDataPools/sparkpool32",
						"name": "sparkpool32",
						"type": "Spark",
						"endpoint": "https://mrgbigpharma.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql import SparkSession\r\n",
							"from pyspark.sql.functions import col, max, coalesce, trunc, lit, add_months\r\n",
							"from pyspark.sql.window import Window\r\n",
							"from pyspark.sql import functions as F\r\n",
							"from pyspark.sql.functions import to_date\r\n",
							"import pandas as pd\r\n",
							"\r\n",
							"# Create Spark session\r\n",
							"spark = SparkSession.builder.appName(\"Load Planning Book\").getOrCreate()\r\n",
							"\r\n",
							"# Parameters for the Silver layer (ADLS Gen2)\r\n",
							"bucket_name = \"abfss://silver@bigpharma.dfs.core.windows.net/\"\r\n",
							"bucket_name_gold = \"abfss://gold@bigpharma.dfs.core.windows.net/\"\r\n",
							"\r\n",
							"# Paths to Parquet files in ADLS Gen2\r\n",
							"f_sales_path = f\"{bucket_name}/f_sales\"\r\n",
							"f_forecast_path = f\"{bucket_name}/f_forecast\"\r\n",
							"f_pos_data_path = f\"{bucket_name}/f_pos_data\"\r\n",
							"f_wh_data_path = f\"{bucket_name}/f_wh_data\"\r\n",
							"\r\n",
							"# Path to the Gold layer (f_planning_book)\r\n",
							"f_sales_path_gold = f\"{bucket_name_gold}/f_planning_book\"\r\n",
							"\r\n",
							"# Load data from ADLS (tables f_sales, f_forecast, f_pos_data, f_wh_data)\r\n",
							"f_sales = spark.read.parquet(f_sales_path)\r\n",
							"f_forecast = spark.read.parquet(f_forecast_path)\r\n",
							"f_pos_data = spark.read.parquet(f_pos_data_path)\r\n",
							"f_wh_data = spark.read.parquet(f_wh_data_path)\r\n",
							"\r\n",
							"# Get the maximum value of forecast_snapshot from f_forecast\r\n",
							"current_month_snapshot = f_forecast.agg(F.max(\"forecast_snapshot\")).collect()[0][0]\r\n",
							"current_month_snapshot = to_date(lit(current_month_snapshot), \"yyyy-MM-dd\")\r\n",
							"last_month_snapshot = F.add_months(F.lit(current_month_snapshot), -1)\r\n",
							"\r\n",
							"f_forecast_filtered = f_forecast.filter(F.col(\"forecast_snapshot\").isin(current_month_snapshot, last_month_snapshot))\r\n",
							"\r\n",
							"# Filter for the current and last month\r\n",
							"f_forecast_current = f_forecast_filtered.filter((F.col(\"forecast_date\") >= current_month_snapshot) & (F.col(\"forecast_snapshot\") == current_month_snapshot))\r\n",
							"f_forecast_last = f_forecast_filtered.filter((F.col(\"forecast_date\") >= last_month_snapshot) & (F.col(\"forecast_snapshot\") == last_month_snapshot))\r\n",
							"\r\n",
							"# Filter f_sales\r\n",
							"f_sales_current = f_sales.filter(F.col(\"shipped_date\") < current_month_snapshot)\r\n",
							"f_sales_last = f_sales.filter(F.col(\"shipped_date\") < last_month_snapshot)\r\n",
							"\r\n",
							"f_pos_data_current = f_pos_data.filter(F.col(\"transaction_date\") < current_month_snapshot)\r\n",
							"f_pos_data_last = f_pos_data.filter(F.col(\"transaction_date\") < last_month_snapshot)\r\n",
							"\r\n",
							"f_wh_data_current = f_wh_data.filter(F.col(\"transaction_date\") < current_month_snapshot)\r\n",
							"f_wh_data_last = f_wh_data.filter(F.col(\"transaction_date\") < last_month_snapshot)\r\n",
							"\r\n",
							"# Unified column list\r\n",
							"common_columns = [\r\n",
							"    \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\",\r\n",
							"    \"quantity\", \"amount\", \"unit_price\",\r\n",
							"    \"whrs_sell_in_quantity\", \"whrs_open_quantity\", \"whrs_end_quantity\",\r\n",
							"    \"whrs_sell_in_amount\", \"whrs_open_amount\", \"whrs_end_amount\",\r\n",
							"    \"pos_sell_out_quantity\", \"pos_open_quantity\", \"pos_end_quantity\",\r\n",
							"    \"pos_sell_out_amount\", \"pos_open_amount\", \"pos_end_amount\",\r\n",
							"    \"discount\"\r\n",
							"]\r\n",
							"\r\n",
							"# Normalize f_forecast (keeps the original forecast_snapshot)\r\n",
							"f_forecast_current_norm = f_forecast_current \\\r\n",
							"    .withColumnRenamed(\"forecast_date\", \"financial_date\") \\\r\n",
							"    .selectExpr(\r\n",
							"        \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\",\r\n",
							"        \"quantity\", \"amount\", \"unit_price\",\r\n",
							"        \"whrs_sell_in_quantity\", \"whrs_open_quantity\", \"whrs_end_quantity\",\r\n",
							"        \"whrs_sell_in_amount\", \"whrs_open_amount\", \"whrs_end_amount\",\r\n",
							"        \"pos_sell_out_quantity\", \"pos_open_quantity\", \"pos_end_quantity\",\r\n",
							"        \"pos_sell_out_amount\", \"pos_open_amount\", \"pos_end_amount\",\r\n",
							"        \"0.0 as discount\"  # If discount is of type double\r\n",
							"    )\r\n",
							"\r\n",
							"f_forecast_last_norm = f_forecast_last \\\r\n",
							"    .withColumnRenamed(\"forecast_date\", \"financial_date\") \\\r\n",
							"    .selectExpr(\r\n",
							"        \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\",\r\n",
							"        \"quantity\", \"amount\", \"unit_price\",\r\n",
							"        \"whrs_sell_in_quantity\", \"whrs_open_quantity\", \"whrs_end_quantity\",\r\n",
							"        \"whrs_sell_in_amount\", \"whrs_open_amount\", \"whrs_end_amount\",\r\n",
							"        \"pos_sell_out_quantity\", \"pos_open_quantity\", \"pos_end_quantity\",\r\n",
							"        \"pos_sell_out_amount\", \"pos_open_amount\", \"pos_end_amount\",\r\n",
							"        \"0.0 as discount\"  # If discount is of type double\r\n",
							"    )\r\n",
							"\r\n",
							"# Normalize f_sales\r\n",
							"f_sales_current_norm = f_sales_current \\\r\n",
							"    .withColumnRenamed(\"shipped_date\", \"financial_date\") \\\r\n",
							"    .withColumn(\"forecast_snapshot\", current_month_snapshot) \\\r\n",
							"    .selectExpr(\r\n",
							"        \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\",\r\n",
							"        \"quantity\", \"amount\", \"unit_price\",\r\n",
							"        \"0 as whrs_sell_in_quantity\", \"0 as whrs_open_quantity\", \"0 as whrs_end_quantity\",\r\n",
							"        \"0 as whrs_sell_in_amount\", \"0 as whrs_open_amount\", \"0 as whrs_end_amount\",\r\n",
							"        \"0 as pos_sell_out_quantity\", \"0 as pos_open_quantity\", \"0 as pos_end_quantity\",\r\n",
							"        \"0 as pos_sell_out_amount\", \"0 as pos_open_amount\", \"0 as pos_end_amount\",\r\n",
							"        \"discount\"\r\n",
							"    )\r\n",
							"\r\n",
							"f_sales_last_norm = f_sales_last \\\r\n",
							"    .withColumnRenamed(\"shipped_date\", \"financial_date\") \\\r\n",
							"    .withColumn(\"forecast_snapshot\", last_month_snapshot) \\\r\n",
							"    .selectExpr(\r\n",
							"        \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\",\r\n",
							"        \"quantity\", \"amount\", \"unit_price\",\r\n",
							"        \"0 as whrs_sell_in_quantity\", \"0 as whrs_open_quantity\", \"0 as whrs_end_quantity\",\r\n",
							"        \"0 as whrs_sell_in_amount\", \"0 as whrs_open_amount\", \"0 as whrs_end_amount\",\r\n",
							"        \"0 as pos_sell_out_quantity\", \"0 as pos_open_quantity\", \"0 as pos_end_quantity\",\r\n",
							"        \"0 as pos_sell_out_amount\", \"0 as pos_open_amount\", \"0 as pos_end_amount\",\r\n",
							"        \"discount\"\r\n",
							"    )\r\n",
							"\r\n",
							"# Normalize f_pos_data_path\r\n",
							"f_pos_data_current_norm = f_pos_data_current \\\r\n",
							"    .withColumnRenamed(\"transaction_date\", \"financial_date\") \\\r\n",
							"    .withColumn(\"forecast_snapshot\", current_month_snapshot) \\\r\n",
							"    .selectExpr(\r\n",
							"        \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\",\r\n",
							"        \"0 as quantity\", \"0 as amount\", \"unit_price\",\r\n",
							"        \"0 as whrs_sell_in_quantity\", \"0 as whrs_open_quantity\", \"0 as whrs_end_quantity\",\r\n",
							"        \"0 as whrs_sell_in_amount\", \"0 as whrs_open_amount\", \"0 as whrs_end_amount\",\r\n",
							"        \"pos_sell_out_quantity\", \"pos_open_quantity\", \"pos_end_quantity\",\r\n",
							"        \"pos_sell_out_amount\", \"pos_open_amount\", \"pos_end_amount\",\r\n",
							"        \"0 as discount\"\r\n",
							"    )\r\n",
							"\r\n",
							"f_pos_data_last_norm = f_pos_data_last \\\r\n",
							"    .withColumnRenamed(\"transaction_date\", \"financial_date\") \\\r\n",
							"    .withColumn(\"forecast_snapshot\", last_month_snapshot) \\\r\n",
							"    .selectExpr(\r\n",
							"        \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\",\r\n",
							"        \"0 as quantity\", \"0 as amount\", \"unit_price\",\r\n",
							"        \"0 as whrs_sell_in_quantity\", \"0 as whrs_open_quantity\", \"0 as whrs_end_quantity\",\r\n",
							"        \"0 as whrs_sell_in_amount\", \"0 as whrs_open_amount\", \"0 as whrs_end_amount\",\r\n",
							"        \"pos_sell_out_quantity\", \"pos_open_quantity\", \"pos_end_quantity\",\r\n",
							"        \"pos_sell_out_amount\", \"pos_open_amount\", \"pos_end_amount\",\r\n",
							"        \"0 as discount\"\r\n",
							"    )\r\n",
							"\r\n",
							"# Normalize f_wh_data_path\r\n",
							"f_wh_data_current_norm = f_wh_data_current \\\r\n",
							"    .withColumnRenamed(\"transaction_date\", \"financial_date\") \\\r\n",
							"    .withColumn(\"forecast_snapshot\", current_month_snapshot) \\\r\n",
							"    .selectExpr(\r\n",
							"        \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\",\r\n",
							"        \"0 as quantity\", \"0 as amount\", \"unit_price\",\r\n",
							"        \"whrs_sell_in_quantity\", \"whrs_open_quantity\", \"whrs_end_quantity\",\r\n",
							"        \"whrs_sell_in_amount\", \"whrs_open_amount\", \"whrs_end_amount\",\r\n",
							"        \"0 as pos_sell_out_quantity\", \"0 as pos_open_quantity\", \"0 as pos_end_quantity\",\r\n",
							"        \"0 as pos_sell_out_amount\", \"0 as pos_open_amount\", \"0 as pos_end_amount\",\r\n",
							"        \"0 as discount\"\r\n",
							"    )\r\n",
							"\r\n",
							"f_wh_data_last_norm = f_wh_data_last \\\r\n",
							"    .withColumnRenamed(\"transaction_date\", \"financial_date\") \\\r\n",
							"    .withColumn(\"forecast_snapshot\", last_month_snapshot) \\\r\n",
							"    .selectExpr(\r\n",
							"        \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\",\r\n",
							"        \"0 as quantity\", \"0 as amount\", \"unit_price\",\r\n",
							"        \"whrs_sell_in_quantity\", \"whrs_open_quantity\", \"whrs_end_quantity\",\r\n",
							"        \"whrs_sell_in_amount\", \"whrs_open_amount\", \"whrs_end_amount\",\r\n",
							"        \"0 as pos_sell_out_quantity\", \"0 as pos_open_quantity\", \"0 as pos_end_quantity\",\r\n",
							"        \"0 as pos_sell_out_amount\", \"0 as pos_open_amount\", \"0 as pos_end_amount\",\r\n",
							"        \"0 as discount\"\r\n",
							"    )\r\n",
							"\r\n",
							"    # UNION of all DataFrames\r\n",
							"\r\n",
							"f_forecast_current_norm\r\n",
							"f_forecast_last_norm\r\n",
							"f_sales_current_norm \r\n",
							"f_sales_last_norm\r\n",
							"f_pos_data_current_norm\r\n",
							"f_pos_data_last_norm\r\n",
							"f_wh_data_current_norm\r\n",
							"f_wh_data_last_norm\r\n",
							"\r\n",
							"final_df = f_forecast_current_norm.unionByName(f_forecast_last_norm, allowMissingColumns=True) \\\r\n",
							"    .unionByName(f_sales_current_norm, allowMissingColumns=True) \\\r\n",
							"    .unionByName(f_sales_last_norm, allowMissingColumns=True) \\\r\n",
							"    .unionByName(f_pos_data_current_norm, allowMissingColumns=True) \\\r\n",
							"    .unionByName(f_pos_data_last_norm, allowMissingColumns=True) \\\r\n",
							"    .unionByName(f_wh_data_current_norm, allowMissingColumns=True) \\\r\n",
							"    .unionByName(f_wh_data_last_norm, allowMissingColumns=True) \r\n",
							"\r\n",
							"bucket_name_gold = \"gold\"\r\n",
							"\r\n",
							"\r\n",
							"aggregated_df = final_df.groupBy(\r\n",
							"    \"product_id\", \"country_id\", \"financial_date\", \"forecast_snapshot\"\r\n",
							").agg(\r\n",
							"    # Sum for numerical columns\r\n",
							"    F.sum(\"quantity\").alias(\"quantity\"),\r\n",
							"    F.sum(\"amount\").alias(\"amount\"),\r\n",
							"    F.avg(\"unit_price\").alias(\"unit_price\"),\r\n",
							"    \r\n",
							"    # Sum for other columns\r\n",
							"    F.sum(\"whrs_sell_in_quantity\").alias(\"whrs_sell_in_quantity\"),\r\n",
							"    F.sum(\"whrs_open_quantity\").alias(\"whrs_open_quantity\"),\r\n",
							"    F.sum(\"whrs_end_quantity\").alias(\"whrs_end_quantity\"),\r\n",
							"    F.sum(\"whrs_sell_in_amount\").alias(\"whrs_sell_in_amount\"),\r\n",
							"    F.sum(\"whrs_open_amount\").alias(\"whrs_open_amount\"),\r\n",
							"    F.sum(\"whrs_end_amount\").alias(\"whrs_end_amount\"),\r\n",
							"    \r\n",
							"    F.sum(\"pos_sell_out_quantity\").alias(\"pos_sell_out_quantity\"),\r\n",
							"    F.sum(\"pos_open_quantity\").alias(\"pos_open_quantity\"),\r\n",
							"    F.sum(\"pos_end_quantity\").alias(\"pos_end_quantity\"),\r\n",
							"    F.sum(\"pos_sell_out_amount\").alias(\"pos_sell_out_amount\"),\r\n",
							"    F.sum(\"pos_open_amount\").alias(\"pos_open_amount\"),\r\n",
							"    F.sum(\"pos_end_amount\").alias(\"pos_end_amount\"),\r\n",
							"    \r\n",
							"    # Aggregation for discount (average)\r\n",
							"    F.sum(\"discount\").alias(\"discount\")\r\n",
							")\r\n",
							"\r\n",
							"\r\n",
							"# Load data\r\n",
							"df_pandas = aggregated_df.toPandas()\r\n",
							"\r\n",
							"df_pandas = df_pandas.drop(columns=['discount', 'unit_price'])\r\n",
							"\r\n",
							"# Unpivoting (melt)\r\n",
							"df_melted = df_pandas.melt(\r\n",
							"   id_vars=['product_id', 'country_id', 'financial_date', 'forecast_snapshot'],\r\n",
							"    var_name=\"original_column\",\r\n",
							"    value_name=\"value\"\r\n",
							")\r\n",
							"\r\n",
							"# Create a new 'measure' column based on the presence of 'quantity' or 'amount' in the column name\r\n",
							"df_melted[\"Measure\"] = df_melted[\"original_column\"].apply(\r\n",
							"    lambda x: \"EA\" if \"quantity\" in x.lower() else \"GTS\" if \"amount\" in x.lower() else \"unknown\"\r\n",
							")\r\n",
							"\r\n",
							"# Mapping column names to new formats\r\n",
							"measure_mapping = {\r\n",
							"    'quantity': 'Ex-Factory',\r\n",
							"    'amount': 'Ex-Factory',\r\n",
							"    'whrs_sell_in_quantity': 'Sales to pharmacies',\r\n",
							"    'whrs_open_quantity': 'Open Stock',\r\n",
							"    'whrs_end_quantity': 'Close Stock',\r\n",
							"    'whrs_sell_in_amount': 'Sales to pharmacies',\r\n",
							"    'whrs_open_amount': 'Open Stock',\r\n",
							"    'whrs_end_amount': 'Close Stock',\r\n",
							"    'pos_sell_out_quantity': 'Consumer Off Take',\r\n",
							"    'pos_open_quantity': 'Open Stock Pharmacies',\r\n",
							"    'pos_end_quantity': 'Close Stock Pharmacies',\r\n",
							"    'pos_sell_out_amount': 'Consumer Off Take',\r\n",
							"    'pos_open_amount': 'Open Stock Pharmacies',\r\n",
							"    'pos_end_amount': 'Close Stock Pharmacies'\r\n",
							"}\r\n",
							"\r\n",
							"# Apply the mapping\r\n",
							"df_melted[\"original_column\"] = df_melted[\"original_column\"].replace(measure_mapping)\r\n",
							"\r\n",
							"# Remove rows with missing values\r\n",
							"df_melted = df_melted.dropna(subset=[\"original_column\", \"value\"])\r\n",
							"\r\n",
							"# Pivoting data\r\n",
							"df_pivoted = df_melted.pivot_table(\r\n",
							"    index=['product_id', 'country_id', 'financial_date', 'forecast_snapshot', 'Measure'],  \r\n",
							"    columns='original_column',\r\n",
							"    values='value',\r\n",
							"    aggfunc='first'  # or 'sum', if you want to sum values\r\n",
							").reset_index()\r\n",
							"\r\n",
							"# Remove the column name after pivoting\r\n",
							"df_pivoted.columns.name = None\r\n",
							"\r\n",
							"# Find the maximum date\r\n",
							"max_forecast_snapshot = df_pivoted[\"forecast_snapshot\"].max()\r\n",
							"\r\n",
							"# Add a status column\r\n",
							"df_pivoted[\"Version\"] =  df_pivoted[\"forecast_snapshot\"].apply(\r\n",
							"    lambda x: \"Current\" if x == max_forecast_snapshot else \"Last\"\r\n",
							")\r\n",
							"\r\n",
							"\r\n",
							"# Path to the Gold layer (f_planning_book)\r\n",
							"f_sales_path_gold = f\"{bucket_name_gold}/f_planning_book_unpivot\"\r\n",
							"\r\n",
							"df_spark = spark.createDataFrame(df_pivoted)\r\n",
							"\r\n",
							"df_spark = df_spark.withColumnRenamed('product_id', 'IdProduct') \\\r\n",
							"    .withColumnRenamed('country_id', 'IDCountry') \\\r\n",
							"    .withColumnRenamed('financial_date', 'Date') \\\r\n",
							"    .withColumnRenamed('Close Stock', 'Close_Stock') \\\r\n",
							"    .withColumnRenamed('Ex-Factory', 'Ex_Factory') \\\r\n",
							"    .withColumnRenamed('Open Stock', 'Open_Stock') \\\r\n",
							"    .withColumnRenamed('Open Stock Pharmacies', 'Open_Stock_Pharmacies') \\\r\n",
							"    .withColumnRenamed('Sales to pharmacies', 'Sales_to_pharmacies') \\\r\n",
							"    .withColumnRenamed('Close Stock Pharmacies', 'Close_Stock_Pharmacies')\\\r\n",
							"    .withColumnRenamed('Consumer Off Take', 'Consumer_Off_Take')\r\n",
							"\r\n",
							"df_spark.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").format(\"delta\").save(\"abfss://gold@bigpharma.dfs.core.windows.net/f_planning_book\")\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": 8
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/F_POS_LOAD_SQL')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load_Silver"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "f67d9330-3c2a-4ae4-b8c8-ea3a60bcc905"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_sparksql",
						"display_name": "sql"
					},
					"language_info": {
						"name": "sql"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							}
						},
						"source": [
							"%%pyspark\n",
							"## 1. Load data from Bronze and Customers as temporary views\n",
							"df_bronze = spark.read.option(\"header\", \"true\").csv(\n",
							"    \"abfss://bronze@bigpharma.dfs.core.windows.net/MinIo_Pharmacies/*/*/*.csv\"\n",
							")\n",
							"df_bronze.createOrReplaceTempView(\"bronze_pos\")\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "sparksql"
							}
						},
						"source": [
							"%%sql\n",
							"CREATE DATABASE IF NOT EXISTS silver;\n",
							"\n",
							"-- ============================================\n",
							"-- 2. Prepare data – latest update + monthly aggregation\n",
							"-- ============================================\n",
							"--CREATE OR REPLACE TEMP VIEW aggregated_bronze_pos AS\n",
							"--SELECT \n",
							"--    product_id,\n",
							"--    country_id,\n",
							"--    max(update_date) as pos_update_date,    \n",
							"--    TRUNC(transaction_date, \"MM\") AS transaction_date,\n",
							"--    SUM(pos_sell_out_quantity) AS pos_sell_out_quantity,\n",
							"--    SUM(pos_open_quantity) AS pos_open_quantity,\n",
							"--    SUM(pos_end_quantity) AS pos_end_quantity,\n",
							"--    ROUND(SUM(pos_sell_out_quantity * unit_price), 2) AS pos_sell_out_amount,\n",
							"--    ROUND(SUM(pos_open_quantity * unit_price), 2) AS pos_open_amount,\n",
							"--    ROUND(SUM(pos_end_quantity * unit_price), 2) AS pos_end_amount,\n",
							"--    ROUND(SUM(pos_sell_out_quantity * unit_price) / NULLIF(SUM(pos_sell_out_quantity), 0), 2) AS unit_price\n",
							"--FROM  bronze_pos\n",
							"--GROUP BY product_id, country_id, TRUNC(transaction_date, \"MM\");\n",
							"\n",
							"\n",
							"\n",
							"CREATE OR REPLACE TEMP VIEW aggregated_bronze_pos AS\n",
							"WITH pos_with_max_date AS (\n",
							"    SELECT \n",
							"        product_id,\n",
							"        country_id,\n",
							"        update_date,\n",
							"        transaction_date,\n",
							"        pos_sell_out_quantity,\n",
							"        pos_open_quantity,\n",
							"        pos_end_quantity,\n",
							"        unit_price,\n",
							"        MAX(update_date) OVER (PARTITION BY product_id, country_id, TRUNC(transaction_date, \"MM\")) AS max_update_date\n",
							"    FROM bronze_pos\n",
							")\n",
							"SELECT \n",
							"    product_id,\n",
							"    country_id,\n",
							"    MAX(update_date) AS pos_update_date,    \n",
							"    TRUNC(transaction_date, \"MM\") AS transaction_date,\n",
							"    SUM(pos_sell_out_quantity) AS pos_sell_out_quantity,\n",
							"    SUM(pos_open_quantity) AS pos_open_quantity,\n",
							"    SUM(pos_end_quantity) AS pos_end_quantity,\n",
							"    ROUND(SUM(pos_sell_out_quantity * unit_price), 2) AS pos_sell_out_amount,\n",
							"    ROUND(SUM(pos_open_quantity * unit_price), 2) AS pos_open_amount,\n",
							"    ROUND(SUM(pos_end_quantity * unit_price), 2) AS pos_end_amount,\n",
							"    ROUND(SUM(pos_sell_out_quantity * unit_price) / NULLIF(SUM(pos_sell_out_quantity), 0), 2) AS unit_price\n",
							"FROM pos_with_max_date\n",
							"WHERE update_date = max_update_date\n",
							"GROUP BY product_id, country_id, TRUNC(transaction_date, \"MM\");\n",
							"\n",
							"\n",
							"-- ============================================\n",
							"-- 3. Create the target table (Silver) if it does not exist\n",
							"-- ============================================\n",
							"CREATE TABLE IF NOT EXISTS silver.f_pos_data\n",
							"USING delta\n",
							"LOCATION 'abfss://silver@bigpharma.dfs.core.windows.net/f_pos_data'\n",
							"AS\n",
							"SELECT * FROM aggregated_bronze_pos\n",
							"WHERE 1 = 0;\n",
							"\n",
							"-- Filter new or updated records\n",
							"CREATE OR REPLACE TEMP VIEW filter_aggregated_bronze_pos AS\n",
							"SELECT * from aggregated_bronze_pos n \n",
							"where NOT EXISTS (\n",
							"  SELECT product_id FROM silver.f_pos_data s \n",
							"  WHERE s.product_id = n.product_id \n",
							"    AND s.country_id = n.country_id\n",
							"    AND s.pos_update_date = n.pos_update_date\n",
							"    AND s.transaction_date = n.transaction_date\n",
							");\n",
							"\n",
							"-- ============================================\n",
							"-- 4. MERGE INTO (UPSERT) data into the Delta table\n",
							"-- ============================================\n",
							"\n",
							"MERGE INTO silver.f_pos_data AS target\n",
							"USING filter_aggregated_bronze_pos AS source\n",
							"ON target.product_id = source.product_id\n",
							"   AND target.country_id = source.country_id\n",
							"   AND target.transaction_date = source.transaction_date\n",
							"\n",
							"WHEN MATCHED THEN\n",
							"  UPDATE SET\n",
							"    target.pos_sell_out_quantity = source.pos_sell_out_quantity,\n",
							"    target.pos_open_quantity = source.pos_open_quantity,\n",
							"    target.pos_end_quantity = source.pos_end_quantity,\n",
							"    target.pos_sell_out_amount = source.pos_sell_out_amount,\n",
							"    target.pos_open_amount = source.pos_open_amount,\n",
							"    target.pos_end_amount = source.pos_end_amount,\n",
							"    target.unit_price = source.unit_price,\n",
							"    target.pos_update_date = source.pos_update_date \n",
							"\n",
							"WHEN NOT MATCHED THEN\n",
							"  INSERT (\n",
							"    product_id,\n",
							"    country_id,\n",
							"    transaction_date,\n",
							"    pos_sell_out_quantity,\n",
							"    pos_open_quantity,\n",
							"    pos_end_quantity,\n",
							"    pos_sell_out_amount,\n",
							"    pos_open_amount,\n",
							"    pos_end_amount,\n",
							"    unit_price,\n",
							"    pos_update_date \n",
							"  )\n",
							"  VALUES (\n",
							"    source.product_id,\n",
							"    source.country_id,\n",
							"    source.transaction_date,\n",
							"    source.pos_sell_out_quantity,\n",
							"    source.pos_open_quantity,\n",
							"    source.pos_end_quantity,\n",
							"    source.pos_sell_out_amount,\n",
							"    source.pos_open_amount,\n",
							"    source.pos_end_amount,\n",
							"    source.unit_price,\n",
							"    source.pos_update_date \n",
							"  );\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/F_SALES_LOAD_SQL')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load_Silver"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c5138b6f-e6ed-4ac8-9d66-4f61e327c727"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_sparksql",
						"display_name": "sql"
					},
					"language_info": {
						"name": "sql"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/825011b4-60a2-4e32-a6f1-221c4bc009ef/resourceGroups/lakehouse/providers/Microsoft.Synapse/workspaces/mrgbigpharma/bigDataPools/sparkpool32",
						"name": "sparkpool32",
						"type": "Spark",
						"endpoint": "https://mrgbigpharma.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"CREATE DATABASE IF NOT EXISTS silver;\n",
							"\n",
							"-- 1. Temporary views on files from ADLS Gen2\n",
							"\n",
							"CREATE OR REPLACE TEMP VIEW bronze_orders\n",
							"USING parquet\n",
							"OPTIONS (\n",
							"  path 'abfss://bronze@bigpharma.dfs.core.windows.net/Erp/orders'\n",
							");\n",
							"\n",
							"CREATE OR REPLACE TEMP VIEW bronze_order_details\n",
							"USING parquet\n",
							"OPTIONS (\n",
							"  path 'abfss://bronze@bigpharma.dfs.core.windows.net/Erp/order_details'\n",
							");\n",
							"\n",
							"CREATE OR REPLACE TEMP VIEW d_customers\n",
							"USING parquet\n",
							"OPTIONS (\n",
							"  path 'abfss://silver@bigpharma.dfs.core.windows.net/d_customers'\n",
							");\n",
							"\n",
							"-- 2. Create target table (if not exists)\n",
							"CREATE TABLE IF NOT EXISTS silver.f_sales (\n",
							"    country_id STRING,\n",
							"    product_id STRING,\n",
							"    shipped_date DATE,\n",
							"    quantity DOUBLE,\n",
							"    discount DOUBLE,\n",
							"    amount DOUBLE,\n",
							"    unit_price DOUBLE,\n",
							"    order_details_update_date DATE,\n",
							"    order_update_date DATE\n",
							")\n",
							"USING DELTA\n",
							"LOCATION 'abfss://silver@bigpharma.dfs.core.windows.net/f_sales/';\n",
							"\n",
							"-- 2. Prepare data – latest update + monthly-level aggregation\n",
							"\n",
							"--CREATE OR REPLACE TEMP VIEW aggregated_bronze_orders AS\n",
							"--WITH orders_trunc AS (\n",
							"--    SELECT\n",
							"--        order_id,\n",
							"--        customer_id,\n",
							"--        TRUNC(order_date, 'MM') AS order_date,\n",
							"--        TRUNC(required_date, 'MM') AS required_date,\n",
							"--        TRUNC(shipped_date, 'MM') AS shipped_date,\n",
							"--        update_date AS order_update_date\n",
							"--    FROM bronze_orders\n",
							"--),\n",
							"--joined_orders AS (\n",
							"--    SELECT\n",
							"--        o.order_id,\n",
							"--        c.country_id,\n",
							"--        od.product_id,\n",
							"--        o.shipped_date,\n",
							"--        od.unit_price,\n",
							"--        od.quantity,\n",
							"--        od.discount,\n",
							"--        o.order_date,\n",
							"--        od.update_date AS order_details_update_date,\n",
							"--        o.order_update_date\n",
							"--    FROM orders_trunc o\n",
							"--    JOIN bronze_order_details od ON o.order_id = od.order_id\n",
							"--    JOIN d_customers c ON o.customer_id = c.customer_id\n",
							"--),\n",
							"--final_orders AS (\n",
							"--    SELECT\n",
							"--        country_id,\n",
							"--        product_id,\n",
							"--        shipped_date,\n",
							"--        MAX(order_details_update_date) AS order_details_update_date,\n",
							"--        MAX(order_update_date) AS order_update_date,\n",
							"--        SUM(quantity) AS quantity,\n",
							"--        SUM(discount) AS discount,\n",
							"--        ROUND(SUM(quantity * unit_price), 2) AS amount,\n",
							"--        ROUND(SUM(quantity * unit_price) / NULLIF(SUM(quantity), 0), 2) AS unit_price\n",
							"--    FROM joined_orders\n",
							"--    GROUP BY country_id, product_id, shipped_date\n",
							"--)\n",
							"--SELECT * FROM final_orders;\n",
							"\n",
							"CREATE OR REPLACE TEMP VIEW aggregated_bronze_orders AS\n",
							"WITH orders_trunc AS (\n",
							"    SELECT\n",
							"        order_id,\n",
							"        customer_id,\n",
							"        TRUNC(order_date, 'MM') AS order_date,\n",
							"        TRUNC(required_date, 'MM') AS required_date,\n",
							"        TRUNC(shipped_date, 'MM') AS shipped_date,\n",
							"        update_date AS order_update_date\n",
							"    FROM bronze_orders\n",
							"),\n",
							"joined_orders AS (\n",
							"    SELECT\n",
							"        o.order_id,\n",
							"        c.country_id,\n",
							"        od.product_id,\n",
							"        o.shipped_date,\n",
							"        od.unit_price,\n",
							"        od.quantity,\n",
							"        od.discount,\n",
							"        o.order_date,\n",
							"        od.update_date AS order_details_update_date,\n",
							"        o.order_update_date\n",
							"    FROM orders_trunc o\n",
							"    JOIN bronze_order_details od ON o.order_id = od.order_id\n",
							"    JOIN d_customers c ON o.customer_id = c.customer_id\n",
							"),\n",
							"orders_with_max_update AS (\n",
							"    SELECT\n",
							"        order_id,\n",
							"        country_id,\n",
							"        product_id,\n",
							"        shipped_date,\n",
							"        order_details_update_date,\n",
							"        order_update_date,\n",
							"        quantity,\n",
							"        discount,\n",
							"        unit_price,\n",
							"        MAX(order_details_update_date) OVER (PARTITION BY product_id, country_id, shipped_date) AS max_order_details_update_date,\n",
							"        MAX(order_update_date) OVER (PARTITION BY product_id, country_id, shipped_date) AS max_order_update_date\n",
							"    FROM joined_orders\n",
							")\n",
							"SELECT\n",
							"    country_id,\n",
							"    product_id,\n",
							"    shipped_date,\n",
							"    order_details_update_date,\n",
							"    order_update_date,\n",
							"    SUM(quantity) AS quantity,\n",
							"    SUM(discount) AS discount,\n",
							"    ROUND(SUM(quantity * unit_price), 2) AS amount,\n",
							"    ROUND(SUM(quantity * unit_price) / NULLIF(SUM(quantity), 0), 2) AS unit_price\n",
							"FROM orders_with_max_update\n",
							"WHERE order_details_update_date = max_order_details_update_date\n",
							"  AND order_update_date = max_order_update_date\n",
							"GROUP BY country_id, product_id, shipped_date, order_details_update_date, order_update_date;\n",
							"\n",
							"\n",
							"-- Filter new or updated records\n",
							"CREATE OR REPLACE TEMP VIEW filter_aggregated_bronze_orders AS\n",
							"SELECT * FROM aggregated_bronze_orders n \n",
							"WHERE NOT EXISTS (\n",
							"  SELECT product_id FROM silver.f_sales s \n",
							"  WHERE s.product_id = n.product_id \n",
							"    AND s.shipped_date = n.shipped_date\n",
							"    AND s.order_details_update_date = n.order_details_update_date\n",
							"    AND s.order_update_date = n.order_update_date\n",
							");\n",
							"\n",
							"-- 3. Transform and write data to Silver table using MERGE\n",
							"MERGE INTO silver.f_sales AS target\n",
							"USING filter_aggregated_bronze_orders AS source\n",
							"ON target.country_id = source.country_id\n",
							"   AND target.product_id = source.product_id\n",
							"   AND target.shipped_date = source.shipped_date\n",
							"\n",
							"WHEN MATCHED THEN\n",
							"  UPDATE SET\n",
							"    quantity = source.quantity,\n",
							"    discount = source.discount,\n",
							"    amount = source.amount,\n",
							"    unit_price = source.unit_price,\n",
							"    order_details_update_date = source.order_details_update_date,\n",
							"    order_update_date = source.order_update_date \n",
							"\n",
							"WHEN NOT MATCHED THEN\n",
							"  INSERT (\n",
							"    country_id, product_id, shipped_date,\n",
							"    quantity, discount, amount, unit_price, order_details_update_date, order_update_date\n",
							"  )\n",
							"  VALUES (\n",
							"    source.country_id, source.product_id, source.shipped_date,\n",
							"    source.quantity, source.discount, source.amount, source.unit_price, source.order_details_update_date, source.order_update_date\n",
							"  );\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/F_WH_DATA_LOAD_SQL')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load_Silver"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "0690f6ab-fe6b-4337-bb2b-983b5e22e346"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/825011b4-60a2-4e32-a6f1-221c4bc009ef/resourceGroups/lakehouse/providers/Microsoft.Synapse/workspaces/mrgbigpharma/bigDataPools/sparkpool32",
						"name": "sparkpool32",
						"type": "Spark",
						"endpoint": "https://mrgbigpharma.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							}
						},
						"source": [
							"%%pyspark\n",
							"## 1. Load data from Bronze and Customers as temporary views\n",
							"df_bronze = spark.read.option(\"header\", \"true\").csv(\n",
							"    \"abfss://bronze@bigpharma.dfs.core.windows.net/MinIo_Distributors/*/*/*.csv\"\n",
							")\n",
							"df_bronze.createOrReplaceTempView(\"bronze_inventory\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "sparksql"
							}
						},
						"source": [
							"%%sql\n",
							"CREATE DATABASE IF NOT EXISTS silver;\n",
							"\n",
							"-- 1. Create a temporary view from the Silver d_customers table\n",
							"CREATE OR REPLACE TEMP VIEW silver_d_customers\n",
							"USING delta\n",
							"OPTIONS (\n",
							"  path 'abfss://silver@bigpharma.dfs.core.windows.net/d_customers'\n",
							");\n",
							"\n",
							"-- 2. Create the target Silver table as Delta (if it does not exist)\n",
							"CREATE TABLE IF NOT EXISTS silver.f_wh_data (\n",
							"  product_id STRING,\n",
							"  country_id STRING,\n",
							"  transaction_date DATE,\n",
							"  whrs_sell_in_quantity DOUBLE,\n",
							"  whrs_open_quantity DOUBLE,\n",
							"  whrs_end_quantity DOUBLE,\n",
							"  whrs_sell_in_amount DOUBLE,\n",
							"  whrs_open_amount DOUBLE,\n",
							"  whrs_end_amount DOUBLE,\n",
							"  unit_price DOUBLE,\n",
							"  whrs_update_date DATE\n",
							")\n",
							"USING DELTA\n",
							"LOCATION 'abfss://silver@bigpharma.dfs.core.windows.net/f_wh_data/';\n",
							"\n",
							"-- 3. Join and aggregate warehouse data\n",
							"--CREATE OR REPLACE TEMP VIEW aggregated_bronze_wh AS\n",
							"--    WITH join_wh AS (\n",
							"--        SELECT\n",
							"--            inv.*,\n",
							"--            c.country_id\n",
							"--        FROM bronze_inventory inv\n",
							"--        JOIN silver_d_customers c ON inv.customer_id = c.customer_id\n",
							"--    ),\n",
							"--    select_wh AS (\n",
							"--        SELECT\n",
							"--            product_id,\n",
							"--            country_id,\n",
							"--            update_date AS whrs_update_date,\n",
							"--            TRUNC(transaction_date, 'MM') AS transaction_date,\n",
							"--            unit_price,\n",
							"--            whrs_sell_in_quantity,\n",
							"--            whrs_open_quantity,\n",
							"--            whrs_end_quantity\n",
							"--        FROM join_wh\n",
							"--    ),\n",
							"--    aggregated AS (\n",
							"--        SELECT\n",
							"--            product_id,\n",
							"--            country_id,\n",
							"--            transaction_date,\n",
							"--            MAX(whrs_update_date) AS whrs_update_date,\n",
							"--            SUM(whrs_sell_in_quantity) AS whrs_sell_in_quantity,\n",
							"--            SUM(whrs_open_quantity) AS whrs_open_quantity,\n",
							"--            SUM(whrs_end_quantity) AS whrs_end_quantity,\n",
							"--            ROUND(SUM(whrs_sell_in_quantity * unit_price), 2) AS whrs_sell_in_amount,\n",
							"--            ROUND(SUM(whrs_open_quantity * unit_price), 2) AS whrs_open_amount,\n",
							"--            ROUND(SUM(whrs_end_quantity * unit_price), 2) AS whrs_end_amount,\n",
							"--            ROUND(SUM(whrs_sell_in_quantity * unit_price) / NULLIF(SUM(whrs_sell_in_quantity), 0), 2) AS unit_price\n",
							"--        FROM select_wh\n",
							"--        GROUP BY product_id, country_id, transaction_date\n",
							"--    )\n",
							"--SELECT * FROM aggregated;\n",
							"\n",
							"---\n",
							"CREATE OR REPLACE TEMP VIEW aggregated_bronze_wh AS\n",
							"WITH join_wh AS (\n",
							"    SELECT\n",
							"        inv.*,\n",
							"        c.country_id\n",
							"    FROM bronze_inventory inv\n",
							"    JOIN silver_d_customers c ON inv.customer_id = c.customer_id\n",
							"),\n",
							"select_wh AS (\n",
							"    SELECT\n",
							"        product_id,\n",
							"        country_id,\n",
							"        update_date AS whrs_update_date,\n",
							"        TRUNC(transaction_date, 'MM') AS transaction_date,\n",
							"        unit_price,\n",
							"        whrs_sell_in_quantity,\n",
							"        whrs_open_quantity,\n",
							"        whrs_end_quantity\n",
							"    FROM join_wh\n",
							"),\n",
							"wh_with_max_update AS (\n",
							"    SELECT\n",
							"        product_id,\n",
							"        country_id,\n",
							"        transaction_date,\n",
							"        whrs_update_date,\n",
							"        unit_price,\n",
							"        whrs_sell_in_quantity,\n",
							"        whrs_open_quantity,\n",
							"        whrs_end_quantity,\n",
							"        MAX(whrs_update_date) OVER (PARTITION BY product_id, country_id, transaction_date) AS max_whrs_update_date\n",
							"    FROM select_wh\n",
							")\n",
							"SELECT\n",
							"    product_id,\n",
							"    country_id,\n",
							"    transaction_date,\n",
							"    whrs_update_date,\n",
							"    SUM(whrs_sell_in_quantity) AS whrs_sell_in_quantity,\n",
							"    SUM(whrs_open_quantity) AS whrs_open_quantity,\n",
							"    SUM(whrs_end_quantity) AS whrs_end_quantity,\n",
							"    ROUND(SUM(whrs_sell_in_quantity * unit_price), 2) AS whrs_sell_in_amount,\n",
							"    ROUND(SUM(whrs_open_quantity * unit_price), 2) AS whrs_open_amount,\n",
							"    ROUND(SUM(whrs_end_quantity * unit_price), 2) AS whrs_end_amount,\n",
							"    ROUND(SUM(whrs_sell_in_quantity * unit_price) / NULLIF(SUM(whrs_sell_in_quantity), 0), 2) AS unit_price\n",
							"FROM wh_with_max_update\n",
							"WHERE whrs_update_date = max_whrs_update_date\n",
							"GROUP BY product_id, country_id, transaction_date, whrs_update_date;\n",
							"\n",
							"\n",
							"\n",
							"\n",
							"\n",
							"-- 4. Filter new or updated records\n",
							"CREATE OR REPLACE TEMP VIEW filter_aggregated_bronze_wh AS\n",
							"SELECT * FROM aggregated_bronze_wh n \n",
							"WHERE NOT EXISTS (\n",
							"  SELECT product_id FROM silver.f_wh_data s \n",
							"  WHERE s.product_id = n.product_id \n",
							"    AND s.country_id = n.country_id\n",
							"    AND s.transaction_date = n.transaction_date\n",
							"    AND s.whrs_update_date = n.whrs_update_date\n",
							");\n",
							"\n",
							"-- 5. MERGE the data into the Silver table with aggregation and filtering\n",
							"MERGE INTO silver.f_wh_data AS target\n",
							"USING filter_aggregated_bronze_wh AS source\n",
							"ON target.product_id = source.product_id\n",
							"   AND target.country_id = source.country_id\n",
							"   AND target.transaction_date = source.transaction_date\n",
							"WHEN MATCHED THEN\n",
							"  UPDATE SET\n",
							"    whrs_sell_in_quantity = source.whrs_sell_in_quantity,\n",
							"    whrs_open_quantity = source.whrs_open_quantity,\n",
							"    whrs_end_quantity = source.whrs_end_quantity,\n",
							"    whrs_sell_in_amount = source.whrs_sell_in_amount,\n",
							"    whrs_open_amount = source.whrs_open_amount,\n",
							"    whrs_end_amount = source.whrs_end_amount,\n",
							"    unit_price = source.unit_price,\n",
							"    whrs_update_date = source.whrs_update_date\n",
							"WHEN NOT MATCHED THEN\n",
							"  INSERT (\n",
							"    product_id, country_id, transaction_date,\n",
							"    whrs_sell_in_quantity, whrs_open_quantity, whrs_end_quantity,\n",
							"    whrs_sell_in_amount, whrs_open_amount, whrs_end_amount,\n",
							"    unit_price, whrs_update_date\n",
							"  )\n",
							"  VALUES (\n",
							"    source.product_id, source.country_id, source.transaction_date,\n",
							"    source.whrs_sell_in_quantity, source.whrs_open_quantity, source.whrs_end_quantity,\n",
							"    source.whrs_sell_in_amount, source.whrs_open_amount, source.whrs_end_amount,\n",
							"    source.unit_price, source.whrs_update_date\n",
							"  );\n",
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LOAD_DISTRIBUTORS_DATA_PY')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load_Bronze"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "aedba073-77a4-4e2f-906a-33b13cfdd744"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/825011b4-60a2-4e32-a6f1-221c4bc009ef/resourceGroups/lakehouse/providers/Microsoft.Synapse/workspaces/mrgbigpharma/bigDataPools/sparkpool32",
						"name": "sparkpool32",
						"type": "Spark",
						"endpoint": "https://mrgbigpharma.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"##LOAD_DISTRIBUTORS_DATA_PY\n",
							"\n",
							"from notebookutils import mssparkutils\n",
							"from urllib.parse import unquote\n",
							"\n",
							"access_key = mssparkutils.credentials.getSecret('keylakehouse','s3-access-key','AzureKeyVault')\n",
							"secret_key = mssparkutils.credentials.getSecret('keylakehouse','s3-secret-key', 'AzureKeyVault')\n",
							"\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://20.215.33.25:9000\")\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
							"\n",
							"\n",
							"from pyspark.sql.utils import AnalysisException\n",
							"from pyspark.sql.functions import input_file_name\n",
							"\n",
							"# Path to DeltaTable with the list of processed files\n",
							"processed_files_path = \"abfss://bronze@bigpharma.dfs.core.windows.net/MinIo_Distributors/Processed_Files_Logs\"\n",
							"\n",
							"try:\n",
							"    processed_df = spark.read.format(\"delta\").load(processed_files_path)\n",
							"    print(\"Loaded existing Delta file with processed files.\")\n",
							"except AnalysisException:\n",
							"    processed_df = spark.createDataFrame([], \"filepaths STRING\")\n",
							"    print(\"Delta file does not exist. Creating a new empty DataFrame.\")\n",
							"\n",
							"\n",
							"# MinIO parameters\n",
							"bucket_name = \"distributors\"\n",
							"folder_path = \"data/country=*/closed_month=*/\"\n",
							"\n",
							"# Read all CSV files from MinIO (including subfolders)\n",
							"files_metadata = spark.read \\\n",
							"    .option(\"header\", \"true\") \\\n",
							"    .csv(f\"s3a://{bucket_name}/{folder_path}\") \\\n",
							"    .withColumn(\"input_file\", input_file_name())\n",
							"# Extract file names\n",
							"all_files = files_metadata.select(\"input_file\").rdd.flatMap(lambda x: x).collect()\n",
							"\n",
							"all_filenames = [file.split(\"/\")[-1] for file in all_files]\n",
							"all_paths = list(set([file.split(\",\")[-1] for file in all_files]))\n",
							"\n",
							"# List of already processed files\n",
							"processed_filenames = [row.filepaths for row in processed_df.collect()]\n",
							"\n",
							"# Find new files to process\n",
							"new_paths = [paths for paths in all_paths if unquote(paths) not in processed_filenames]\n",
							"\n",
							"print(f\"Found {len(new_paths)} new paths to process.\")\n",
							"# Process new files\n",
							"for path in new_paths:\n",
							"    file_path = path\n",
							"    file_path = file_path.split(\"?\")[0]\n",
							"    print(file_path)\n",
							"    file_name = [part for part in file_path.split(\"/\") if \"closed_month=\" in part][0].split(\"=\")[1] #file_path.split(\"/\")[-1]\n",
							"    country_name = [segment for segment in file_path.split(\"/\") if segment.startswith(\"country=\")][0].split(\"=\")[1]\n",
							"    print(f\"Loading path: {file_path}\")\n",
							"    print(f\"Loading file: {file_name}\")\n",
							"    print(f\"Loading path: {country_name}\")\n",
							"\n",
							"    target_path = f\"abfss://bronze@bigpharma.dfs.core.windows.net/MinIo_Distributors/{country_name}/{file_name}\"\n",
							"\n",
							"    print(f\"Target path: {target_path}\")\n",
							"    print(f\"Loading file: {file_path}\")\n",
							"\n",
							"    try:\n",
							"        df_new = spark.read.option(\"header\", \"true\").csv(unquote(file_path))\n",
							"        df_new.write.option(\"header\", \"true\").mode(\"overwrite\").csv(unquote(target_path))\n",
							"        print(f\"Saved file to ADLS: {target_path}\")\n",
							"    except Exception as e:\n",
							"        print(f\"Error processing file {file_path}: {e}\")\n",
							"\n",
							"# Update the list of processed files\n",
							"if new_paths:\n",
							"    new_files_df = spark.createDataFrame([(unquote(path),) for path in new_paths], [\"filepaths\"])\n",
							"    processed_files_updated = processed_df.union(new_files_df)\n",
							"    processed_files_updated.show()\n",
							"    # Save updated list in Delta format\n",
							"    processed_files_updated.write.format(\"delta\") \\\n",
							"        .mode(\"overwrite\") \\\n",
							"        .save(processed_files_path)\n",
							"\n",
							"    print(f\"Updated the processed files list in Delta with {processed_files_updated.count()} entries.\")\n",
							"else:\n",
							"    print(\"No new files to process.\")\n",
							""
						],
						"outputs": [],
						"execution_count": 1
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LOAD_PHARMACIES_DATA_PY')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Load_Bronze"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkpool32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "437bbfc6-5857-4e4e-a293-636062b082d7"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/825011b4-60a2-4e32-a6f1-221c4bc009ef/resourceGroups/lakehouse/providers/Microsoft.Synapse/workspaces/mrgbigpharma/bigDataPools/sparkpool32",
						"name": "sparkpool32",
						"type": "Spark",
						"endpoint": "https://mrgbigpharma.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"#LOAD_PHARMACIES_DATA_PY\n",
							"\n",
							"from notebookutils import mssparkutils\n",
							"from urllib.parse import unquote\n",
							"\n",
							"access_key = mssparkutils.credentials.getSecret('keylakehouse','s3-access-key','AzureKeyVault')\n",
							"secret_key = mssparkutils.credentials.getSecret('keylakehouse','s3-secret-key', 'AzureKeyVault')\n",
							"\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://20.215.33.25:9000\")\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
							"spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
							"\n",
							"from pyspark.sql.utils import AnalysisException\n",
							"from pyspark.sql.functions import input_file_name\n",
							"\n",
							"# Path to DeltaTable with the list of processed files\n",
							"processed_files_path = \"abfss://bronze@bigpharma.dfs.core.windows.net/MinIo_Pharmacies/Processed_Files_Logs\"\n",
							"\n",
							"try:\n",
							"    processed_df = spark.read.format(\"delta\").load(processed_files_path)\n",
							"    print(\"Loaded existing Delta file with processed files.\")\n",
							"except AnalysisException:\n",
							"   processed_df = spark.createDataFrame([], \"filepaths STRING\")\n",
							"   print(\"Delta file does not exist. Creating a new empty DataFrame.\")\n",
							"\n",
							"\n",
							"# MinIO parameters\n",
							"bucket_name = \"pharmacies\"\n",
							"folder_path = \"data/country=*/closed_month=*/\"\n",
							"\n",
							"# Read all CSV files from MinIO (including subfolders)\n",
							"files_metadata = spark.read \\\n",
							"    .option(\"header\", \"true\") \\\n",
							"    .csv(f\"s3a://{bucket_name}/{folder_path}*\") \\\n",
							"    .withColumn(\"input_file\", input_file_name())\n",
							"\n",
							"# Extract file names\n",
							"all_files = files_metadata.select(\"input_file\").rdd.flatMap(lambda x: x).collect()\n",
							"\n",
							"all_filenames = [file.split(\"/\")[-1] for file in all_files]\n",
							"all_paths = list(set([file.split(\",\")[-1] for file in all_files]))\n",
							"\n",
							"# List of already processed files\n",
							"processed_filenames = [row.filepaths for row in processed_df.collect()]\n",
							"\n",
							"# Find new files to process\n",
							"new_paths = [paths for paths in all_paths if unquote(paths) not in processed_filenames]\n",
							"\n",
							"print(f\"Found {len(new_paths)} new paths to process.\")\n",
							"\n",
							"# Process new files\n",
							"for path in new_paths:\n",
							"    file_path = path\n",
							"    file_path = file_path.split(\"?\")[0]\n",
							"    print(file_path)\n",
							"    file_name = [part for part in file_path.split(\"/\") if \"closed_month=\" in part][0].split(\"=\")[1] #file_path.split(\"/\")[-1]\n",
							"    country_name = [segment for segment in file_path.split(\"/\") if segment.startswith(\"country=\")][0].split(\"=\")[1]\n",
							"    print(f\"Loading path: {file_path}\")\n",
							"    print(f\"Loading file: {file_name}\")\n",
							"    print(f\"Loading path: {country_name}\")\n",
							"\n",
							"    target_path = f\"abfss://bronze@bigpharma.dfs.core.windows.net/MinIo_Pharmacies/{country_name}/{file_name}\"\n",
							"\n",
							"    print(f\"Loading file: {file_path}\")\n",
							"\n",
							"    try:\n",
							"        df_new = spark.read.option(\"header\", \"true\").csv(unquote(file_path))\n",
							"        df_new.write.option(\"header\", \"true\").mode(\"overwrite\").csv(unquote(target_path))\n",
							"        print(f\"Saved file to ADLS: {target_path}\")\n",
							"    except Exception as e:\n",
							"        print(f\"Error processing file {file_path}: {e}\")\n",
							"\n",
							"# Update the list of processed files\n",
							"if new_paths:\n",
							"    new_files_df = spark.createDataFrame([(unquote(path),) for path in new_paths], [\"pathname\"])\n",
							"    processed_files_updated = processed_df.union(new_files_df)\n",
							"    processed_files_updated.show()\n",
							"    # Save updated list in Delta format\n",
							"    processed_files_updated.write.format(\"delta\") \\\n",
							"        .mode(\"overwrite\") \\\n",
							"       .save(processed_files_path)\n",
							"\n",
							"    print(f\"Updated the processed files list in Delta with {processed_files_updated.count()} entries.\")\n",
							"else:\n",
							"    print(\"No new files to process.\")\n",
							""
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sparkpool32')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 5
				},
				"autoScale": {
					"enabled": false,
					"maxNodeCount": 3,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.4",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "polandcentral"
		}
	]
}