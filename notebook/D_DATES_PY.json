{
	"name": "D_DATES_PY",
	"properties": {
		"folder": {
			"name": "Load Gold"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "ff4131b5-2156-4771-aa83-c4f9f21883bb"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import (\n",
					"    col, lit, year, month, quarter, weekofyear, dayofmonth,\n",
					"    dayofweek, dayofyear, date_format, current_timestamp, when, concat_ws\n",
					")\n",
					"from datetime import datetime, timedelta\n",
					"import pandas as pd\n",
					"\n",
					"# Define the date range for the calendar table\n",
					"start_year = 2020\n",
					"end_year = 2025\n",
					"\n",
					"# Create a list of dates from start_date to end_date using pandas\n",
					"start_date = datetime(start_year, 1, 1)\n",
					"end_date = datetime(end_year, 12, 31)\n",
					"date_range = pd.date_range(start=start_date, end=end_date).to_frame(index=False, name=\"Date\")\n",
					"\n",
					"# Convert the pandas DataFrame to a Spark DataFrame\n",
					"df = spark.createDataFrame(date_range)\n",
					"\n",
					"# Add calendar-related columns to enrich the date dimension\n",
					"df = df.withColumn(\"Year\", year(\"Date\")) \\\n",
					"       .withColumn(\"Month\", month(\"Date\")) \\\n",
					"       .withColumn(\"Quarter\", quarter(\"Date\")) \\\n",
					"       .withColumn(\"WeekOfYear\", weekofyear(\"Date\")) \\\n",
					"       .withColumn(\"Day\", dayofmonth(\"Date\")) \\\n",
					"       .withColumn(\"DayOfWeek\", dayofweek(\"Date\")) \\\n",
					"       .withColumn(\"DayOfYear\", dayofyear(\"Date\")) \\\n",
					"       .withColumn(\"DayName\", date_format(\"Date\", \"EEEE\")) \\\n",
					"       .withColumn(\"MonthName\", date_format(\"Date\", \"MMMM\")) \\\n",
					"       .withColumn(\"NowMonth\", month(current_timestamp())) \\\n",
					"       .withColumn(\"YTD_BTG\", when(col(\"Month\") < col(\"NowMonth\"), \"YTD\").otherwise(\"BTG\")) \\\n",
					"       .withColumn(\"FY\", lit(\"FY\")) \\\n",
					"       .withColumn(\"QuarterStr\", concat_ws(\"\", lit(\"Q\"), col(\"Quarter\").cast(\"string\"))) \\\n",
					"       .withColumn(\"KeyYearMonth\", concat_ws(\"\", col(\"Year\").cast(\"string\"), col(\"Month\").cast(\"string\"))) \\\n",
					"       .withColumn(\"KeyYearQuarter\", concat_ws(\"\", col(\"Year\").cast(\"string\"), col(\"QuarterStr\"))) \\\n",
					"       .withColumn(\"KeyYearYTDBTG\", concat_ws(\"\", col(\"Year\").cast(\"string\"), col(\"YTD_BTG\"))) \\\n",
					"       .withColumn(\"KeyYearFY\", concat_ws(\"\", col(\"Year\").cast(\"string\"), col(\"FY\")))\n",
					"\n",
					"\n",
					"# Remove unused composite key columns\n",
					"df = df.drop(\"KeyYearMonth\", \"KeyYearQuarter\", \"KeyYearYTDBTG\", \"KeyYearFY\")\n",
					"\n",
					"# Optional: reorder columns to desired output format\n",
					"columns_order = [\"Year\", \"QuarterStr\", \"Month\", \"Date\", \"YTD_BTG\"]\n",
					"\n",
					"# Save the resulting date dimension to a Delta Lake table in Azure Data Lake Storage\n",
					"df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").format(\"delta\").save(\"abfss://gold@bigpharma.dfs.core.windows.net/d_dates\")\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"    spark.sql(f\"\"\"\n",
					"        CREATE TABLE gold.d_customers\n",
					"        USING DELTA\n",
					"        LOCATION 'abfss://gold@bigpharma.dfs.core.windows.net/d_dates'\n",
					"    \"\"\")"
				],
				"execution_count": null
			}
		]
	}
}